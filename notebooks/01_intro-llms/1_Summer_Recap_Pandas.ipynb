{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summer Recap: Data Analysis with Pandas\n",
    "\n",
    "* * * \n",
    "\n",
    "<div class=\"alert alert-success\">  \n",
    "    \n",
    "### Learning Objectives \n",
    "    \n",
    "* Review fundamental pandas operations for data manipulation and analysis.\n",
    "* Apply data cleaning techniques to real-world social science datasets.\n",
    "* Practice exploratory data analysis using descriptive statistics and basic visualizations.\n",
    "* Demonstrate ability to filter, group, and aggregate data using pandas methods.\n",
    "* Evaluate LLM-generated code for accuracy and best practices.\n",
    "</div>\n",
    "\n",
    "### Icons Used in This Notebook\n",
    "üîî **Question**: A quick question to help you understand what's going on.<br>\n",
    "ü•ä **Challenge**: Interactive excersise. We'll work through these in the workshop!<br>\n",
    "üí° **Tip**: How to do something a bit more efficiently or effectively.<br>\n",
    "‚ö†Ô∏è **Warning:** Heads-up about tricky stuff or common mistakes.<br>\n",
    "ü§ñ **AI Generated**: Code generated by an LLM that we'll test and debug.<br>\n",
    "\n",
    "### Sections\n",
    "1. [Data Loading and Initial Exploration](#section1)\n",
    "2. [Data Cleaning and Basic Operations](#section2)\n",
    "3. [Exploratory Data Analysis](#section3)\n",
    "4. [Text Analysis Fundamentals](#section4)\n",
    "5. [Working with LLM-Generated Code](#section5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "\n",
    "# Data Loading and Initial Exploration\n",
    "\n",
    "Today we'll work with data from Reddit's \"Am I the Asshole?\" (AITA) subreddit. This dataset contains posts where people describe situations and ask for community judgment about their behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (20000, 18)\n",
      "\n",
      "Column names:\n",
      "['idint', 'idstr', 'created', 'self', 'nsfw', 'author', 'title', 'url', 'selftext', 'score', 'subreddit', 'distinguish', 'textlen', 'num_comments', 'flair_text', 'flair_css_class', 'augmented_at', 'augmented_count']\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../../data/aita_top_submissions.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumn names:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idint</th>\n",
       "      <th>idstr</th>\n",
       "      <th>created</th>\n",
       "      <th>self</th>\n",
       "      <th>nsfw</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>distinguish</th>\n",
       "      <th>textlen</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>flair_text</th>\n",
       "      <th>flair_css_class</th>\n",
       "      <th>augmented_at</th>\n",
       "      <th>augmented_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>427576402</td>\n",
       "      <td>t3_72kg2a</td>\n",
       "      <td>1506433689</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ritsku</td>\n",
       "      <td>AITA for breaking up with my girlfriend becaus...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My girlfriend recently went to the beach with ...</td>\n",
       "      <td>679.0</td>\n",
       "      <td>AmItheAsshole</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4917.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>no a--holes here</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>551887974</td>\n",
       "      <td>t3_94kvhi</td>\n",
       "      <td>1533404095</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hhhhhhffff678</td>\n",
       "      <td>AITA for banning smoking in my house and telli...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My parents smoke like chimneys. I used to as w...</td>\n",
       "      <td>832.0</td>\n",
       "      <td>AmItheAsshole</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2076.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>asshole</td>\n",
       "      <td>ass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552654542</td>\n",
       "      <td>t3_951az2</td>\n",
       "      <td>1533562299</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>creepatthepool</td>\n",
       "      <td>AITA? Creep wears skimpy bathing suit to pool</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hi guys. Throwaway for obv reasons.\\n\\nI'm a f...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>AmItheAsshole</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1741.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>Shitpost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>556350346</td>\n",
       "      <td>t3_978ioa</td>\n",
       "      <td>1534254641</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pauly104</td>\n",
       "      <td>AITA for eating steak in front of my vegan GF?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yesterday night, me and my GF decided to go ou...</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>AmItheAsshole</td>\n",
       "      <td>NaN</td>\n",
       "      <td>416.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>not the a-hole</td>\n",
       "      <td>not</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>560929656</td>\n",
       "      <td>t3_99yo3c</td>\n",
       "      <td>1535126620</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ThatSpencerGuy</td>\n",
       "      <td>AITA for not wanting to cook my mother-in-law ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My wife and I are vegetarians, much to my in-l...</td>\n",
       "      <td>349.0</td>\n",
       "      <td>AmItheAsshole</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1158.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>not the a-hole</td>\n",
       "      <td>not</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       idint      idstr     created  self  nsfw          author  \\\n",
       "0  427576402  t3_72kg2a  1506433689   1.0   0.0          Ritsku   \n",
       "1  551887974  t3_94kvhi  1533404095   1.0   0.0   hhhhhhffff678   \n",
       "2  552654542  t3_951az2  1533562299   1.0   0.0  creepatthepool   \n",
       "3  556350346  t3_978ioa  1534254641   1.0   0.0        Pauly104   \n",
       "4  560929656  t3_99yo3c  1535126620   1.0   0.0  ThatSpencerGuy   \n",
       "\n",
       "                                               title  url  \\\n",
       "0  AITA for breaking up with my girlfriend becaus...  NaN   \n",
       "1  AITA for banning smoking in my house and telli...  NaN   \n",
       "2      AITA? Creep wears skimpy bathing suit to pool  NaN   \n",
       "3     AITA for eating steak in front of my vegan GF?  NaN   \n",
       "4  AITA for not wanting to cook my mother-in-law ...  NaN   \n",
       "\n",
       "                                            selftext   score      subreddit  \\\n",
       "0  My girlfriend recently went to the beach with ...   679.0  AmItheAsshole   \n",
       "1  My parents smoke like chimneys. I used to as w...   832.0  AmItheAsshole   \n",
       "2  Hi guys. Throwaway for obv reasons.\\n\\nI'm a f...    23.0  AmItheAsshole   \n",
       "3  Yesterday night, me and my GF decided to go ou...  1011.0  AmItheAsshole   \n",
       "4  My wife and I are vegetarians, much to my in-l...   349.0  AmItheAsshole   \n",
       "\n",
       "  distinguish  textlen  num_comments        flair_text flair_css_class  \\\n",
       "0         NaN   4917.0         434.0  no a--holes here             NaN   \n",
       "1         NaN   2076.0         357.0           asshole             ass   \n",
       "2         NaN   1741.0         335.0          Shitpost             NaN   \n",
       "3         NaN    416.0         380.0    not the a-hole             not   \n",
       "4         NaN   1158.0         360.0    not the a-hole             not   \n",
       "\n",
       "   augmented_at  augmented_count  \n",
       "0           NaN              NaN  \n",
       "1           NaN              NaN  \n",
       "2           NaN              NaN  \n",
       "3           NaN              NaN  \n",
       "4           NaN              NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge 1: Data Overview\n",
    "\n",
    "Explore the dataset structure and provide a summary of what you find. Use pandas methods to:\n",
    "1. Check the data types of each column\n",
    "2. Look for missing values\n",
    "3. Get basic descriptive statistics for numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîî **Question**: What do you notice about the `selftext` column? What might this tell us about the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "\n",
    "# Data Cleaning and Basic Operations\n",
    "\n",
    "Real-world data often requires cleaning before analysis. Let's examine our dataset for common issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate posts\n",
    "print(f\"Number of duplicate rows: {df.duplicated().sum()}\")\n",
    "\n",
    "# Look at the distribution of some key variables\n",
    "print(f\"\\nScore statistics:\")\n",
    "print(df['score'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge 2: Data Cleaning\n",
    "\n",
    "Clean the dataset by:\n",
    "1. Removing any posts where `selftext` is missing or empty\n",
    "2. Creating a new column called `text_length` that contains the character count of `selftext`\n",
    "3. Filter out posts that are shorter than 100 characters (likely low-quality posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Tip**: Use the `.str.len()` method to get string lengths in pandas. Remember that missing values might cause issues, so handle them first!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Dates\n",
    "\n",
    "The `created` column contains Unix timestamps. Let's convert these to readable dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Unix timestamp to datetime\n",
    "df['created_date'] = pd.to_datetime(df['created'], unit='s')\n",
    "\n",
    "# Extract useful date components\n",
    "df['year'] = df['created_date'].dt.year\n",
    "df['month'] = df['created_date'].dt.month\n",
    "df['day_of_week'] = df['created_date'].dt.day_name()\n",
    "\n",
    "print(\"Date range in dataset:\")\n",
    "print(f\"From: {df['created_date'].min()}\")\n",
    "print(f\"To: {df['created_date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "\n",
    "Now let's explore patterns in the data using pandas grouping and aggregation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge 3: Score Analysis\n",
    "\n",
    "Analyze post popularity by:\n",
    "1. Finding the top 10 posts by score\n",
    "2. Calculating the average score by year\n",
    "3. Determining which day of the week gets the highest average scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment Engagement Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the relationship between text length and engagement\n",
    "correlation = df[['text_length', 'score', 'num_comments']].corr()\n",
    "print(\"Correlation matrix:\")\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîî **Question**: What does the correlation tell us about the relationship between post length and engagement?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge 4: Engagement Categories\n",
    "\n",
    "Create engagement categories and analyze them:\n",
    "1. Create a new column `engagement_level` with categories:\n",
    "   - 'Low': score < 100\n",
    "   - 'Medium': score 100-500\n",
    "   - 'High': score 500-2000\n",
    "   - 'Viral': score > 2000\n",
    "2. Calculate the percentage of posts in each category\n",
    "3. Find the average text length for each engagement level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>\n",
    "\n",
    "# Text Analysis Fundamentals\n",
    "\n",
    "Let's do some basic text analysis to understand the content patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge 5: Text Pattern Analysis\n",
    "\n",
    "Analyze text patterns by:\n",
    "1. Finding posts that contain the word \"family\" (case-insensitive)\n",
    "2. Counting how many posts mention \"wedding\" or \"marriage\"\n",
    "3. Creating a column indicating whether the post is about relationships (contains words like \"boyfriend\", \"girlfriend\", \"husband\", \"wife\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Tip**: Use the `.str.contains()` method with pandas to search for text patterns. The `case=False` parameter makes the search case-insensitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze posting patterns by author\n",
    "author_stats = df['author'].value_counts().head(10)\n",
    "print(\"Top 10 most active authors:\")\n",
    "print(author_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge 6: Final Analysis\n",
    "\n",
    "Combine multiple pandas operations to answer this question:\n",
    "**\"What are the characteristics of the most engaging posts about relationships?\"**\n",
    "\n",
    "Create an analysis that:\n",
    "1. Filters for relationship-related posts\n",
    "2. Groups them by engagement level\n",
    "3. Calculates average text length, comment count, and any other relevant metrics\n",
    "4. Presents a clear summary of your findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è **Warning**: When working with text data, always be mindful of missing values and different text encodings that might cause unexpected results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5'></a>\n",
    "\n",
    "# Working with LLM-Generated Code\n",
    "\n",
    "Now let's explore how Large Language Models can assist with coding tasks. We'll generate some code using an LLM, test it, and discover common pitfalls and best practices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Code with ChatGPT\n",
    "\n",
    "Let's ask ChatGPT to help us create a function that analyzes sentiment patterns in our AITA dataset. Here's the prompt we'll use:\n",
    "\n",
    "**Prompt to ChatGPT:**\n",
    "*\"Write a Python function that takes a pandas DataFrame with a 'selftext' column and creates a simple sentiment analysis. The function should count positive and negative words using predefined word lists, calculate a sentiment score for each post, and return a new DataFrame with sentiment columns added.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ AI Generated Code\n",
    "\n",
    "Below is the code generated by ChatGPT. Let's run it and see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing AI-generated sentiment analysis function...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Test the function\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting AI-generated sentiment analysis function...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m sentiment_df \u001b[38;5;241m=\u001b[39m analyze_sentiment(df)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction completed successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 29\u001b[0m, in \u001b[0;36manalyze_sentiment\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Process each row\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m result_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 29\u001b[0m     text \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselftext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Count positive words\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     pos_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m positive_words \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m text)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "# Generated by ChatGPT - Let's test this code!\n",
    "def analyze_sentiment(df):\n",
    "    \"\"\"\n",
    "    Analyze sentiment of posts in a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df: pandas DataFrame with 'selftext' column\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with added sentiment columns\n",
    "    \"\"\"\n",
    "    # Define positive and negative words\n",
    "    positive_words = ['good', 'great', 'awesome', 'excellent', 'fantastic', 'wonderful', \n",
    "                     'amazing', 'perfect', 'best', 'love', 'happy', 'joy', 'pleased']\n",
    "    \n",
    "    negative_words = ['bad', 'terrible', 'awful', 'horrible', 'worst', 'hate', 'angry', \n",
    "                     'sad', 'upset', 'mad', 'furious', 'disgusting', 'annoying']\n",
    "    \n",
    "    # Create a copy to avoid modifying original\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # Initialize sentiment columns\n",
    "    result_df['positive_count'] = 0\n",
    "    result_df['negative_count'] = 0\n",
    "    result_df['sentiment_score'] = 0.0\n",
    "    \n",
    "    # Process each row\n",
    "    for idx, row in result_df.iterrows():\n",
    "        text = row['selftext'].lower()\n",
    "        \n",
    "        # Count positive words\n",
    "        pos_count = sum(1 for word in positive_words if word in text)\n",
    "        neg_count = sum(1 for word in negative_words if word in text)\n",
    "        \n",
    "        # Calculate sentiment score\n",
    "        total_words = len(text.split())\n",
    "        sentiment_score = (pos_count - neg_count) / total_words\n",
    "        \n",
    "        # Update DataFrame\n",
    "        result_df.loc[idx, 'positive_count'] = pos_count\n",
    "        result_df.loc[idx, 'negative_count'] = neg_count\n",
    "        result_df.loc[idx, 'sentiment_score'] = sentiment_score\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Test the function\n",
    "print(\"Testing AI-generated sentiment analysis function...\")\n",
    "sentiment_df = analyze_sentiment(df)\n",
    "print(\"Function completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîî **Question**: Did the code run successfully? If you got an error, what do you think went wrong?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging the AI Code\n",
    "\n",
    "Let's investigate what went wrong and fix the issues step by step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for missing selftext values:\n",
      "Missing values: 12\n",
      "Total rows: 20000\n"
     ]
    }
   ],
   "source": [
    "# Let's check what's in our dataset first\n",
    "print(\"Checking for missing selftext values:\")\n",
    "print(f\"Missing values: {df['selftext'].isna().sum()}\")\n",
    "print(f\"Total rows: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge 7: Fix the AI Code\n",
    "\n",
    "The AI-generated code has several issues. Can you identify and fix them?\n",
    "\n",
    "**Issues to look for:**\n",
    "1. What happens if `selftext` contains missing values (NaN)?\n",
    "2. What happens if `selftext` is not a string?\n",
    "3. Are there performance issues with this approach?\n",
    "4. Are there edge cases in the sentiment calculation?\n",
    "\n",
    "Write an improved version of the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE - Fix the AI-generated function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## LLM Coding Guidelines\n",
    "\n",
    "Based on our experience with the AI-generated code, let's establish some guidelines for working with LLMs:\n",
    "\n",
    "### ‚úÖ **DO:**\n",
    "- **Provide clear context** and specify desired output format\n",
    "- **Test the code immediately** after generation  \n",
    "- **Check for edge cases** like missing values, empty strings, wrong data types\n",
    "- **Verify performance** - AI often uses inefficient approaches\n",
    "- **Document AI assistance** in comments (e.g., `# Generated with ChatGPT assistance`)\n",
    "- **Understand the code** before using it in your projects\n",
    "- **Ask for explanations** if you don't understand parts of the generated code\n",
    "\n",
    "### ‚ùå **DON'T:**\n",
    "- **Ask for too much at once** - break complex tasks into smaller parts\n",
    "- **Blindly copy-paste** without understanding the code\n",
    "- **Skip testing** - always run and verify the output\n",
    "- **Ignore error handling** - AI often misses edge cases\n",
    "- **Forget to document** AI usage (academic integrity requirement)\n",
    "- **Use AI output** that leads to plagiarism or incorrect work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course Policy on AI Use\n",
    "\n",
    "### üìã **Academic Integrity Guidelines**\n",
    "\n",
    "**You MAY use LLMs as coding assistants IF:**\n",
    "- You **document their use** clearly (in code comments or assignment submissions)\n",
    "- You **personally verify and understand** the solution\n",
    "- You can **explain how the code works** when asked\n",
    "- You **test the code thoroughly** and fix any bugs\n",
    "\n",
    "**Examples of acceptable documentation:**\n",
    "```python\n",
    "# Used ChatGPT to help write this sentiment analysis function\n",
    "# Modified the original output to handle edge cases\n",
    "def my_function():\n",
    "    pass\n",
    "```\n",
    "\n",
    "**You MAY NOT:**\n",
    "- Use AI assistance **without acknowledgment** \n",
    "- Submit AI-generated code that you **don't understand**\n",
    "- Use AI output that leads to **plagiarism or incorrect work**\n",
    "- Claim AI-generated work as **entirely your own**\n",
    "\n",
    "‚ö†Ô∏è **Remember**: Understanding the code is more important than having perfect code. Using LLMs can speed up development, but only if you comprehend what they produce!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge 8: Evaluate AI Output\n",
    "\n",
    "Now it's your turn! Ask ChatGPT (or another LLM) to generate code for one of these tasks:\n",
    "\n",
    "1. **Create a function** that finds the most common words in AITA post titles\n",
    "2. **Generate code** to create a simple visualization of post scores over time  \n",
    "3. **Write a function** that categorizes posts by topic based on keywords\n",
    "\n",
    "**Instructions:**\n",
    "1. Copy your prompt and the AI's response into the cells below\n",
    "2. Test the generated code\n",
    "3. Document any bugs or improvements needed\n",
    "4. Fix the issues and explain what you learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your prompt to the LLM:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR AI-GENERATED CODE HERE\n",
    "# Remember to add a comment acknowledging AI assistance!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Issues found and fixes made:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR IMPROVED VERSION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "## ‚ùó Key Points\n",
    "\n",
    "* Pandas provides powerful tools for loading, cleaning, and exploring real-world datasets.\n",
    "* Always start data analysis by understanding your dataset structure and checking for data quality issues.\n",
    "* The `.groupby()` method is essential for aggregating data and finding patterns across categories.\n",
    "* Text data requires special handling, including case-insensitive searches and pattern matching.\n",
    "* Correlation analysis helps identify relationships between numerical variables.\n",
    "* Creating categorical variables from continuous data enables different types of analysis.\n",
    "* **LLMs can accelerate coding but require careful testing and understanding of generated code.**\n",
    "* **Always document AI assistance and verify that generated code handles edge cases properly.**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
