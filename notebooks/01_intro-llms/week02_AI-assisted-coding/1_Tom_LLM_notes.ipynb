{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5'></a>\n",
    "\n",
    "# Working with LLM-Generated Code\n",
    "\n",
    "Now let's explore how Large Language Models can assist with coding tasks. We'll generate some code using an LLM, test it, and discover common pitfalls and best practices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Code with ChatGPT\n",
    "\n",
    "Let's ask ChatGPT to help us create a function that analyzes sentiment patterns in our AITA dataset. Here's the prompt we'll use:\n",
    "\n",
    "**Prompt to ChatGPT:**\n",
    "*\"Write a Python function that takes a pandas DataFrame with a 'selftext' column and creates a simple sentiment analysis. The function should count positive and negative words using predefined word lists, calculate a sentiment score for each post, and return a new DataFrame with sentiment columns added.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ AI Generated Code\n",
    "\n",
    "Below is the code generated by ChatGPT. Let's run it and see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing AI-generated sentiment analysis function...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Test the function\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting AI-generated sentiment analysis function...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m sentiment_df \u001b[38;5;241m=\u001b[39m analyze_sentiment(df)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction completed successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 29\u001b[0m, in \u001b[0;36manalyze_sentiment\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Process each row\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m result_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 29\u001b[0m     text \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselftext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Count positive words\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     pos_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m positive_words \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m text)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "# Generated by ChatGPT - Let's test this code!\n",
    "def analyze_sentiment(df):\n",
    "    \"\"\"\n",
    "    Analyze sentiment of posts in a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df: pandas DataFrame with 'selftext' column\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with added sentiment columns\n",
    "    \"\"\"\n",
    "    # Define positive and negative words\n",
    "    positive_words = ['good', 'great', 'awesome', 'excellent', 'fantastic', 'wonderful', \n",
    "                     'amazing', 'perfect', 'best', 'love', 'happy', 'joy', 'pleased']\n",
    "    \n",
    "    negative_words = ['bad', 'terrible', 'awful', 'horrible', 'worst', 'hate', 'angry', \n",
    "                     'sad', 'upset', 'mad', 'furious', 'disgusting', 'annoying']\n",
    "    \n",
    "    # Create a copy to avoid modifying original\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # Initialize sentiment columns\n",
    "    result_df['positive_count'] = 0\n",
    "    result_df['negative_count'] = 0\n",
    "    result_df['sentiment_score'] = 0.0\n",
    "    \n",
    "    # Process each row\n",
    "    for idx, row in result_df.iterrows():\n",
    "        text = row['selftext'].lower()\n",
    "        \n",
    "        # Count positive words\n",
    "        pos_count = sum(1 for word in positive_words if word in text)\n",
    "        neg_count = sum(1 for word in negative_words if word in text)\n",
    "        \n",
    "        # Calculate sentiment score\n",
    "        total_words = len(text.split())\n",
    "        sentiment_score = (pos_count - neg_count) / total_words\n",
    "        \n",
    "        # Update DataFrame\n",
    "        result_df.loc[idx, 'positive_count'] = pos_count\n",
    "        result_df.loc[idx, 'negative_count'] = neg_count\n",
    "        result_df.loc[idx, 'sentiment_score'] = sentiment_score\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Test the function\n",
    "print(\"Testing AI-generated sentiment analysis function...\")\n",
    "sentiment_df = analyze_sentiment(df)\n",
    "print(\"Function completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîî **Question**: Did the code run successfully? If you got an error, what do you think went wrong?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging the AI Code\n",
    "\n",
    "Let's investigate what went wrong and fix the issues step by step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for missing selftext values:\n",
      "Missing values: 12\n",
      "Total rows: 20000\n"
     ]
    }
   ],
   "source": [
    "# Let's check what's in our dataset first\n",
    "print(\"Checking for missing selftext values:\")\n",
    "print(f\"Missing values: {df['selftext'].isna().sum()}\")\n",
    "print(f\"Total rows: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge 7: Fix the AI Code\n",
    "\n",
    "The AI-generated code has several issues. Can you identify and fix them?\n",
    "\n",
    "**Issues to look for:**\n",
    "1. What happens if `selftext` contains missing values (NaN)?\n",
    "2. What happens if `selftext` is not a string?\n",
    "3. Are there performance issues with this approach?\n",
    "4. Are there edge cases in the sentiment calculation?\n",
    "\n",
    "Write an improved version of the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE - Fix the AI-generated function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## LLM Coding Guidelines\n",
    "\n",
    "Based on our experience with the AI-generated code, let's establish some guidelines for working with LLMs:\n",
    "\n",
    "### ‚úÖ **DO:**\n",
    "- **Provide clear context** and specify desired output format\n",
    "- **Test the code immediately** after generation  \n",
    "- **Check for edge cases** like missing values, empty strings, wrong data types\n",
    "- **Verify performance** - AI often uses inefficient approaches\n",
    "- **Document AI assistance** in comments (e.g., `# Generated with ChatGPT assistance`)\n",
    "- **Understand the code** before using it in your projects\n",
    "- **Ask for explanations** if you don't understand parts of the generated code\n",
    "\n",
    "### ‚ùå **DON'T:**\n",
    "- **Ask for too much at once** - break complex tasks into smaller parts\n",
    "- **Blindly copy-paste** without understanding the code\n",
    "- **Skip testing** - always run and verify the output\n",
    "- **Ignore error handling** - AI often misses edge cases\n",
    "- **Forget to document** AI usage (academic integrity requirement)\n",
    "- **Use AI output** that leads to plagiarism or incorrect work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course Policy on AI Use\n",
    "\n",
    "### üìã **Academic Integrity Guidelines**\n",
    "\n",
    "**You MAY use LLMs as coding assistants IF:**\n",
    "- You **document their use** clearly (in code comments or assignment submissions)\n",
    "- You **personally verify and understand** the solution\n",
    "- You can **explain how the code works** when asked\n",
    "- You **test the code thoroughly** and fix any bugs\n",
    "\n",
    "**Examples of acceptable documentation:**\n",
    "```python\n",
    "# Used ChatGPT to help write this sentiment analysis function\n",
    "# Modified the original output to handle edge cases\n",
    "def my_function():\n",
    "    pass\n",
    "```\n",
    "\n",
    "**You MAY NOT:**\n",
    "- Use AI assistance **without acknowledgment** \n",
    "- Submit AI-generated code that you **don't understand**\n",
    "- Use AI output that leads to **plagiarism or incorrect work**\n",
    "- Claim AI-generated work as **entirely your own**\n",
    "\n",
    "‚ö†Ô∏è **Remember**: Understanding the code is more important than having perfect code. Using LLMs can speed up development, but only if you comprehend what they produce!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge 8: Evaluate AI Output\n",
    "\n",
    "Now it's your turn! Ask ChatGPT (or another LLM) to generate code for one of these tasks:\n",
    "\n",
    "1. **Create a function** that finds the most common words in AITA post titles\n",
    "2. **Generate code** to create a simple visualization of post scores over time  \n",
    "3. **Write a function** that categorizes posts by topic based on keywords\n",
    "\n",
    "**Instructions:**\n",
    "1. Copy your prompt and the AI's response into the cells below\n",
    "2. Test the generated code\n",
    "3. Document any bugs or improvements needed\n",
    "4. Fix the issues and explain what you learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your prompt to the LLM:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR AI-GENERATED CODE HERE\n",
    "# Remember to add a comment acknowledging AI assistance!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Issues found and fixes made:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR IMPROVED VERSION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "## ‚ùó Key Points\n",
    "\n",
    "* **LLMs can accelerate coding but require careful testing and understanding of generated code.**\n",
    "* **Always document AI assistance and verify that generated code handles edge cases properly.**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
