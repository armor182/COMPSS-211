{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud Computing Lab: Practical Exercises\n",
    "\n",
    "* * * \n",
    "\n",
    "<div class=\"alert alert-success\">  \n",
    "    \n",
    "### Learning Objectives \n",
    "    \n",
    "* Simulate cloud computing concepts locally\n",
    "* Practice with cloud APIs and tools\n",
    "* Run language models efficiently\n",
    "* Estimate and optimize costs\n",
    "* Work with remote computing patterns\n",
    "\n",
    "</div>\n",
    "\n",
    "### Lab Sections\n",
    "1. [Environment Setup](#setup)\n",
    "2. [Simulating Cloud Concepts](#simulate)\n",
    "3. [Cost Estimation](#costs)\n",
    "4. [Remote Computing Patterns](#remote)\n",
    "5. [Running Models Efficiently](#models)\n",
    "6. [Cloud Storage Simulation](#storage)\n",
    "7. [Performance Benchmarking](#benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "\n",
    "# 1. Environment Setup\n",
    "\n",
    "Let's set up our environment to simulate cloud computing concepts locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q psutil pandas matplotlib requests transformers torch\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import psutil\n",
    "import platform\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "\n",
    "print(\"Environment ready!\")\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"Platform: {platform.platform()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Information\n",
    "\n",
    "Understanding your system helps you choose the right cloud instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_info():\n",
    "    \"\"\"Get current system specifications\"\"\"\n",
    "    info = {\n",
    "        \"CPU\": {\n",
    "            \"cores_physical\": psutil.cpu_count(logical=False),\n",
    "            \"cores_logical\": psutil.cpu_count(logical=True),\n",
    "            \"frequency_mhz\": psutil.cpu_freq().current if psutil.cpu_freq() else \"N/A\",\n",
    "            \"usage_percent\": psutil.cpu_percent(interval=1)\n",
    "        },\n",
    "        \"Memory\": {\n",
    "            \"total_gb\": round(psutil.virtual_memory().total / (1024**3), 2),\n",
    "            \"available_gb\": round(psutil.virtual_memory().available / (1024**3), 2),\n",
    "            \"used_percent\": psutil.virtual_memory().percent\n",
    "        },\n",
    "        \"Disk\": {\n",
    "            \"total_gb\": round(psutil.disk_usage('/').total / (1024**3), 2),\n",
    "            \"free_gb\": round(psutil.disk_usage('/').free / (1024**3), 2),\n",
    "            \"used_percent\": psutil.disk_usage('/').percent\n",
    "        }\n",
    "    }\n",
    "    return info\n",
    "\n",
    "# Display system info\n",
    "system_info = get_system_info()\n",
    "for category, details in system_info.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for key, value in details.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='simulate'></a>\n",
    "\n",
    "# 2. Simulating Cloud Concepts\n",
    "\n",
    "Let's simulate key cloud computing concepts locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Virtual Machine Simulation\n",
    "\n",
    "We'll create a simple VM simulator to understand resource allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VirtualMachine:\n",
    "    \"\"\"Simulate a cloud virtual machine\"\"\"\n",
    "    \n",
    "    # GCP Machine Types (simplified)\n",
    "    MACHINE_TYPES = {\n",
    "        \"e2-micro\": {\"vcpus\": 0.25, \"memory_gb\": 1, \"price_hour\": 0.006},\n",
    "        \"e2-small\": {\"vcpus\": 0.5, \"memory_gb\": 2, \"price_hour\": 0.012},\n",
    "        \"e2-medium\": {\"vcpus\": 1, \"memory_gb\": 4, \"price_hour\": 0.027},\n",
    "        \"e2-standard-2\": {\"vcpus\": 2, \"memory_gb\": 8, \"price_hour\": 0.067},\n",
    "        \"e2-standard-4\": {\"vcpus\": 4, \"memory_gb\": 16, \"price_hour\": 0.134},\n",
    "        \"n2-standard-8\": {\"vcpus\": 8, \"memory_gb\": 32, \"price_hour\": 0.388},\n",
    "        \"a2-highgpu-1g\": {\"vcpus\": 12, \"memory_gb\": 85, \"price_hour\": 2.95, \"gpu\": \"A100\"}\n",
    "    }\n",
    "    \n",
    "    def __init__(self, name, machine_type, region=\"us-central1\"):\n",
    "        self.name = name\n",
    "        self.machine_type = machine_type\n",
    "        self.region = region\n",
    "        self.state = \"STOPPED\"\n",
    "        self.start_time = None\n",
    "        self.total_runtime = 0\n",
    "        \n",
    "        if machine_type not in self.MACHINE_TYPES:\n",
    "            raise ValueError(f\"Unknown machine type: {machine_type}\")\n",
    "        \n",
    "        self.specs = self.MACHINE_TYPES[machine_type]\n",
    "    \n",
    "    def start(self):\n",
    "        \"\"\"Start the VM\"\"\"\n",
    "        if self.state == \"RUNNING\":\n",
    "            print(f\"VM {self.name} is already running\")\n",
    "            return\n",
    "        \n",
    "        self.state = \"RUNNING\"\n",
    "        self.start_time = datetime.now()\n",
    "        print(f\"âœ… VM {self.name} started\")\n",
    "        print(f\"   Type: {self.machine_type}\")\n",
    "        print(f\"   vCPUs: {self.specs['vcpus']}, RAM: {self.specs['memory_gb']}GB\")\n",
    "        print(f\"   Cost: ${self.specs['price_hour']}/hour\")\n",
    "    \n",
    "    def stop(self):\n",
    "        \"\"\"Stop the VM\"\"\"\n",
    "        if self.state == \"STOPPED\":\n",
    "            print(f\"VM {self.name} is already stopped\")\n",
    "            return\n",
    "        \n",
    "        runtime = (datetime.now() - self.start_time).total_seconds()\n",
    "        self.total_runtime += runtime\n",
    "        self.state = \"STOPPED\"\n",
    "        \n",
    "        cost = (runtime / 3600) * self.specs['price_hour']\n",
    "        print(f\"ðŸ›‘ VM {self.name} stopped\")\n",
    "        print(f\"   Runtime: {runtime:.0f} seconds\")\n",
    "        print(f\"   Session cost: ${cost:.4f}\")\n",
    "    \n",
    "    def estimate_cost(self, hours):\n",
    "        \"\"\"Estimate cost for running X hours\"\"\"\n",
    "        return hours * self.specs['price_hour']\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"VM({self.name}, {self.machine_type}, {self.state})\"\n",
    "\n",
    "# Create and test VMs\n",
    "vm1 = VirtualMachine(\"test-instance\", \"e2-micro\")\n",
    "vm2 = VirtualMachine(\"ml-instance\", \"e2-standard-4\")\n",
    "\n",
    "print(\"Created VMs:\")\n",
    "print(f\"  {vm1}\")\n",
    "print(f\"  {vm2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate VM lifecycle\n",
    "print(\"Simulating VM operations...\\n\")\n",
    "\n",
    "# Start VM\n",
    "vm1.start()\n",
    "print()\n",
    "\n",
    "# Simulate some work\n",
    "print(\"Doing work for 3 seconds...\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Stop VM\n",
    "vm1.stop()\n",
    "print()\n",
    "\n",
    "# Estimate costs\n",
    "print(\"Cost estimates for vm1 (e2-micro):\")\n",
    "for hours in [1, 24, 24*7, 24*30]:\n",
    "    cost = vm1.estimate_cost(hours)\n",
    "    period = {1: \"1 hour\", 24: \"1 day\", 168: \"1 week\", 720: \"1 month\"}[hours]\n",
    "    print(f\"  {period}: ${cost:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serverless Function Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudFunction:\n",
    "    \"\"\"Simulate a serverless cloud function\"\"\"\n",
    "    \n",
    "    # Pricing: $0.0000004 per invocation + $0.0000025 per GB-second\n",
    "    PRICE_PER_INVOCATION = 0.0000004\n",
    "    PRICE_PER_GB_SECOND = 0.0000025\n",
    "    \n",
    "    def __init__(self, name, memory_mb=256):\n",
    "        self.name = name\n",
    "        self.memory_gb = memory_mb / 1024\n",
    "        self.invocations = 0\n",
    "        self.total_runtime = 0\n",
    "        self.total_cost = 0\n",
    "    \n",
    "    def invoke(self, func, *args, **kwargs):\n",
    "        \"\"\"Run the function and track costs\"\"\"\n",
    "        start = time.time()\n",
    "        \n",
    "        # Run the actual function\n",
    "        result = func(*args, **kwargs)\n",
    "        \n",
    "        # Calculate costs\n",
    "        runtime = time.time() - start\n",
    "        invocation_cost = self.PRICE_PER_INVOCATION\n",
    "        compute_cost = runtime * self.memory_gb * self.PRICE_PER_GB_SECOND\n",
    "        total_cost = invocation_cost + compute_cost\n",
    "        \n",
    "        # Update stats\n",
    "        self.invocations += 1\n",
    "        self.total_runtime += runtime\n",
    "        self.total_cost += total_cost\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def get_stats(self):\n",
    "        \"\"\"Get usage statistics\"\"\"\n",
    "        return {\n",
    "            \"invocations\": self.invocations,\n",
    "            \"total_runtime_s\": round(self.total_runtime, 3),\n",
    "            \"avg_runtime_ms\": round((self.total_runtime / max(self.invocations, 1)) * 1000, 2),\n",
    "            \"total_cost\": f\"${self.total_cost:.8f}\",\n",
    "            \"cost_per_invocation\": f\"${self.total_cost / max(self.invocations, 1):.8f}\"\n",
    "        }\n",
    "\n",
    "# Example serverless function\n",
    "def process_text(text):\n",
    "    \"\"\"Simulate text processing\"\"\"\n",
    "    time.sleep(0.1)  # Simulate processing\n",
    "    return len(text.split())\n",
    "\n",
    "# Create and test cloud function\n",
    "cf = CloudFunction(\"word-counter\", memory_mb=256)\n",
    "\n",
    "# Simulate multiple invocations\n",
    "texts = [\n",
    "    \"Cloud computing is transforming research.\",\n",
    "    \"Serverless functions scale automatically.\",\n",
    "    \"Pay only for what you use with cloud services.\"\n",
    "]\n",
    "\n",
    "print(\"Running serverless functions...\\n\")\n",
    "for text in texts:\n",
    "    word_count = cf.invoke(process_text, text)\n",
    "    print(f\"Processed: '{text[:30]}...' â†’ {word_count} words\")\n",
    "\n",
    "print(\"\\nFunction Statistics:\")\n",
    "for key, value in cf.get_stats().items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='costs'></a>\n",
    "\n",
    "# 3. Cost Estimation\n",
    "\n",
    "Understanding cloud costs is crucial for research budgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudCostCalculator:\n",
    "    \"\"\"Calculate and visualize cloud costs\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.costs = []\n",
    "    \n",
    "    def add_resource(self, name, resource_type, specs, hours):\n",
    "        \"\"\"Add a resource to cost calculation\"\"\"\n",
    "        if resource_type == \"compute\":\n",
    "            cost = specs['price_hour'] * hours\n",
    "        elif resource_type == \"storage\":\n",
    "            # $0.02 per GB per month\n",
    "            cost = specs['size_gb'] * 0.02 * (hours / 720)  # Convert to monthly\n",
    "        elif resource_type == \"network\":\n",
    "            # $0.12 per GB egress\n",
    "            cost = specs['transfer_gb'] * 0.12\n",
    "        else:\n",
    "            cost = 0\n",
    "        \n",
    "        self.costs.append({\n",
    "            'name': name,\n",
    "            'type': resource_type,\n",
    "            'hours': hours,\n",
    "            'cost': cost,\n",
    "            'specs': specs\n",
    "        })\n",
    "    \n",
    "    def get_total_cost(self):\n",
    "        \"\"\"Calculate total cost\"\"\"\n",
    "        return sum(item['cost'] for item in self.costs)\n",
    "    \n",
    "    def get_breakdown(self):\n",
    "        \"\"\"Get cost breakdown by type\"\"\"\n",
    "        breakdown = {}\n",
    "        for item in self.costs:\n",
    "            if item['type'] not in breakdown:\n",
    "                breakdown[item['type']] = 0\n",
    "            breakdown[item['type']] += item['cost']\n",
    "        return breakdown\n",
    "    \n",
    "    def visualize(self):\n",
    "        \"\"\"Create cost visualization\"\"\"\n",
    "        if not self.costs:\n",
    "            print(\"No costs to visualize\")\n",
    "            return\n",
    "        \n",
    "        # Prepare data\n",
    "        df = pd.DataFrame(self.costs)\n",
    "        \n",
    "        # Create subplots\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        \n",
    "        # Pie chart by type\n",
    "        breakdown = self.get_breakdown()\n",
    "        axes[0].pie(breakdown.values(), labels=breakdown.keys(), autopct='%1.1f%%')\n",
    "        axes[0].set_title('Cost Breakdown by Type')\n",
    "        \n",
    "        # Bar chart by resource\n",
    "        df_sorted = df.sort_values('cost', ascending=False).head(10)\n",
    "        axes[1].barh(df_sorted['name'], df_sorted['cost'])\n",
    "        axes[1].set_xlabel('Cost ($)')\n",
    "        axes[1].set_title('Top 10 Resources by Cost')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example: Calculate costs for a research project\n",
    "calc = CloudCostCalculator()\n",
    "\n",
    "# Add compute resources\n",
    "calc.add_resource(\n",
    "    \"development-vm\",\n",
    "    \"compute\",\n",
    "    {\"price_hour\": 0.027},  # e2-medium\n",
    "    hours=8*5*4  # 8 hours/day, 5 days/week, 4 weeks\n",
    ")\n",
    "\n",
    "calc.add_resource(\n",
    "    \"training-vm\",\n",
    "    \"compute\",\n",
    "    {\"price_hour\": 2.95},  # a2-highgpu-1g\n",
    "    hours=4*3  # 4 hours, 3 times\n",
    ")\n",
    "\n",
    "# Add storage\n",
    "calc.add_resource(\n",
    "    \"dataset-storage\",\n",
    "    \"storage\",\n",
    "    {\"size_gb\": 100},\n",
    "    hours=720  # 1 month\n",
    ")\n",
    "\n",
    "# Add network transfer\n",
    "calc.add_resource(\n",
    "    \"data-download\",\n",
    "    \"network\",\n",
    "    {\"transfer_gb\": 50},\n",
    "    hours=1\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"Project Cost Estimation\\n\" + \"=\"*40)\n",
    "for item in calc.costs:\n",
    "    print(f\"{item['name']:<20} ${item['cost']:.2f}\")\n",
    "print(\"=\"*40)\n",
    "print(f\"{'TOTAL':<20} ${calc.get_total_cost():.2f}\")\n",
    "\n",
    "# Visualize\n",
    "calc.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Optimization Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_instance_strategies():\n",
    "    \"\"\"Compare different instance usage strategies\"\"\"\n",
    "    \n",
    "    strategies = {\n",
    "        \"Always On\": {\n",
    "            \"description\": \"Keep instance running 24/7\",\n",
    "            \"hours\": 24 * 30,  # Full month\n",
    "            \"instance\": \"e2-standard-4\",\n",
    "            \"price_hour\": 0.134\n",
    "        },\n",
    "        \"Business Hours\": {\n",
    "            \"description\": \"Run only during work hours (9-5, M-F)\",\n",
    "            \"hours\": 8 * 22,  # 8 hours * 22 work days\n",
    "            \"instance\": \"e2-standard-4\",\n",
    "            \"price_hour\": 0.134\n",
    "        },\n",
    "        \"On Demand\": {\n",
    "            \"description\": \"Start/stop as needed (~2 hrs/day)\",\n",
    "            \"hours\": 2 * 30,  # 2 hours * 30 days\n",
    "            \"instance\": \"e2-standard-4\",\n",
    "            \"price_hour\": 0.134\n",
    "        },\n",
    "        \"Preemptible\": {\n",
    "            \"description\": \"Use cheaper preemptible instances\",\n",
    "            \"hours\": 8 * 22,\n",
    "            \"instance\": \"e2-standard-4 (preemptible)\",\n",
    "            \"price_hour\": 0.040  # ~70% cheaper\n",
    "        },\n",
    "        \"Right-sized\": {\n",
    "            \"description\": \"Use smaller instance that fits needs\",\n",
    "            \"hours\": 24 * 30,\n",
    "            \"instance\": \"e2-medium\",\n",
    "            \"price_hour\": 0.027\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    for name, strategy in strategies.items():\n",
    "        cost = strategy['hours'] * strategy['price_hour']\n",
    "        results.append({\n",
    "            'Strategy': name,\n",
    "            'Description': strategy['description'],\n",
    "            'Instance': strategy['instance'],\n",
    "            'Hours': strategy['hours'],\n",
    "            'Monthly Cost': f\"${cost:.2f}\",\n",
    "            'Savings vs Always On': f\"{(1 - cost/96.48)*100:.1f}%\" if name != \"Always On\" else \"--\"\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "# Compare strategies\n",
    "comparison = compare_instance_strategies()\n",
    "print(\"Cost Optimization Strategies Comparison\\n\")\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "# Visualize savings\n",
    "costs = [float(r['Monthly Cost'].replace('$', '')) for r in comparison.to_dict('records')]\n",
    "strategies = [r['Strategy'] for r in comparison.to_dict('records')]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(strategies, costs, color=['red', 'orange', 'yellow', 'lightgreen', 'green'])\n",
    "plt.ylabel('Monthly Cost ($)')\n",
    "plt.title('Cloud Cost by Usage Strategy')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, cost in zip(bars, costs):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "             f'${cost:.0f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='remote'></a>\n",
    "\n",
    "# 4. Remote Computing Patterns\n",
    "\n",
    "Practice patterns for working with remote systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSH Connection Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSHSimulator:\n",
    "    \"\"\"Simulate SSH connections and commands\"\"\"\n",
    "    \n",
    "    def __init__(self, hostname, username=\"user\"):\n",
    "        self.hostname = hostname\n",
    "        self.username = username\n",
    "        self.connected = False\n",
    "        self.command_history = []\n",
    "    \n",
    "    def connect(self):\n",
    "        \"\"\"Simulate SSH connection\"\"\"\n",
    "        print(f\"Connecting to {self.username}@{self.hostname}...\")\n",
    "        time.sleep(1)  # Simulate connection delay\n",
    "        self.connected = True\n",
    "        print(f\"âœ… Connected to {self.hostname}\")\n",
    "        print(f\"Welcome to Ubuntu 22.04.3 LTS (GNU/Linux 5.15.0)\\n\")\n",
    "        return True\n",
    "    \n",
    "    def run_command(self, command):\n",
    "        \"\"\"Simulate running a command on remote system\"\"\"\n",
    "        if not self.connected:\n",
    "            print(\"Error: Not connected. Run connect() first.\")\n",
    "            return None\n",
    "        \n",
    "        self.command_history.append(command)\n",
    "        print(f\"{self.username}@{self.hostname}:~$ {command}\")\n",
    "        \n",
    "        # Simulate different commands\n",
    "        responses = {\n",
    "            \"pwd\": \"/home/user\",\n",
    "            \"ls\": \"data/  models/  scripts/  results/\",\n",
    "            \"whoami\": self.username,\n",
    "            \"hostname\": self.hostname,\n",
    "            \"free -h\": \"\"\"              total        used        free      shared  buff/cache   available\n",
    "Mem:           15Gi       2.1Gi        10Gi       156Mi       3.2Gi        13Gi\n",
    "Swap:            0B          0B          0B\"\"\",\n",
    "            \"df -h\": \"\"\"Filesystem      Size  Used Avail Use% Mounted on\n",
    "/dev/sda1        30G  5.2G   24G  19% /\n",
    "/dev/sda15      105M  5.2M  100M   5% /boot/efi\"\"\",\n",
    "            \"python3 --version\": \"Python 3.10.12\",\n",
    "            \"nvidia-smi\": \"No NVIDIA GPU detected\"\n",
    "        }\n",
    "        \n",
    "        # Get response or simulate command execution\n",
    "        if command in responses:\n",
    "            output = responses[command]\n",
    "        elif command.startswith(\"echo\"):\n",
    "            output = command.replace(\"echo \", \"\")\n",
    "        elif command.startswith(\"cd\"):\n",
    "            output = \"\"  # cd has no output\n",
    "        else:\n",
    "            output = f\"Command executed: {command}\"\n",
    "        \n",
    "        if output:\n",
    "            print(output)\n",
    "        return output\n",
    "    \n",
    "    def disconnect(self):\n",
    "        \"\"\"Disconnect SSH session\"\"\"\n",
    "        if self.connected:\n",
    "            print(f\"\\nDisconnecting from {self.hostname}...\")\n",
    "            self.connected = False\n",
    "            print(\"Connection closed.\")\n",
    "    \n",
    "    def transfer_file(self, local_file, remote_path, direction=\"upload\"):\n",
    "        \"\"\"Simulate file transfer\"\"\"\n",
    "        if not self.connected:\n",
    "            print(\"Error: Not connected\")\n",
    "            return False\n",
    "        \n",
    "        if direction == \"upload\":\n",
    "            print(f\"Uploading {local_file} to {self.hostname}:{remote_path}\")\n",
    "        else:\n",
    "            print(f\"Downloading {self.hostname}:{remote_path} to {local_file}\")\n",
    "        \n",
    "        # Simulate transfer with progress\n",
    "        for i in range(0, 101, 20):\n",
    "            print(f\"Progress: {i}%\", end=\"\\r\")\n",
    "            time.sleep(0.2)\n",
    "        print(\"Transfer complete!    \")\n",
    "        return True\n",
    "\n",
    "# Test SSH simulator\n",
    "ssh = SSHSimulator(\"vm-instance-1\", \"student\")\n",
    "\n",
    "# Connect and run commands\n",
    "ssh.connect()\n",
    "ssh.run_command(\"pwd\")\n",
    "ssh.run_command(\"ls\")\n",
    "ssh.run_command(\"free -h\")\n",
    "ssh.run_command(\"python3 --version\")\n",
    "\n",
    "# Transfer files\n",
    "print(\"\\n--- File Transfer ---\")\n",
    "ssh.transfer_file(\"model.py\", \"/home/student/models/\", \"upload\")\n",
    "ssh.transfer_file(\"/home/student/results/output.csv\", \"output.csv\", \"download\")\n",
    "\n",
    "# Disconnect\n",
    "ssh.disconnect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remote Job Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoteJob:\n",
    "    \"\"\"Simulate running jobs on remote systems\"\"\"\n",
    "    \n",
    "    def __init__(self, name, script, estimated_time_s=60):\n",
    "        self.name = name\n",
    "        self.script = script\n",
    "        self.estimated_time = estimated_time_s\n",
    "        self.status = \"PENDING\"\n",
    "        self.start_time = None\n",
    "        self.end_time = None\n",
    "        self.output = []\n",
    "    \n",
    "    def start(self):\n",
    "        \"\"\"Start the job\"\"\"\n",
    "        self.status = \"RUNNING\"\n",
    "        self.start_time = datetime.now()\n",
    "        print(f\"ðŸš€ Job '{self.name}' started\")\n",
    "        print(f\"   Script: {self.script}\")\n",
    "        print(f\"   Estimated time: {self.estimated_time}s\")\n",
    "    \n",
    "    def check_status(self):\n",
    "        \"\"\"Check job status\"\"\"\n",
    "        if self.status == \"RUNNING\":\n",
    "            elapsed = (datetime.now() - self.start_time).total_seconds()\n",
    "            progress = min(elapsed / self.estimated_time * 100, 100)\n",
    "            print(f\"Job '{self.name}': {self.status} ({progress:.0f}% complete)\")\n",
    "        else:\n",
    "            print(f\"Job '{self.name}': {self.status}\")\n",
    "        return self.status\n",
    "    \n",
    "    def simulate_completion(self):\n",
    "        \"\"\"Simulate job completion\"\"\"\n",
    "        if self.status == \"RUNNING\":\n",
    "            self.status = \"COMPLETED\"\n",
    "            self.end_time = datetime.now()\n",
    "            runtime = (self.end_time - self.start_time).total_seconds()\n",
    "            \n",
    "            # Generate fake output\n",
    "            self.output = [\n",
    "                f\"Processing started at {self.start_time}\",\n",
    "                \"Loading data...\",\n",
    "                \"Running analysis...\",\n",
    "                \"Results computed successfully\",\n",
    "                f\"Total runtime: {runtime:.2f} seconds\"\n",
    "            ]\n",
    "            \n",
    "            print(f\"âœ… Job '{self.name}' completed in {runtime:.2f}s\")\n",
    "    \n",
    "    def get_output(self):\n",
    "        \"\"\"Get job output\"\"\"\n",
    "        if self.status == \"COMPLETED\":\n",
    "            return \"\\n\".join(self.output)\n",
    "        else:\n",
    "            return f\"Job is {self.status}. No output available yet.\"\n",
    "\n",
    "# Simulate batch job processing\n",
    "jobs = [\n",
    "    RemoteJob(\"data_preprocessing\", \"preprocess.py\", 30),\n",
    "    RemoteJob(\"model_training\", \"train_model.py\", 120),\n",
    "    RemoteJob(\"evaluation\", \"evaluate.py\", 45)\n",
    "]\n",
    "\n",
    "print(\"Submitting batch jobs...\\n\")\n",
    "\n",
    "# Start all jobs\n",
    "for job in jobs:\n",
    "    job.start()\n",
    "    time.sleep(0.5)\n",
    "\n",
    "print(\"\\n--- Monitoring Jobs ---\")\n",
    "# Check status\n",
    "for job in jobs:\n",
    "    job.check_status()\n",
    "\n",
    "print(\"\\n--- Simulating Completion ---\")\n",
    "# Complete jobs\n",
    "for job in jobs:\n",
    "    job.simulate_completion()\n",
    "    print(f\"Output preview: {job.get_output().split(chr(10))[0]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='models'></a>\n",
    "\n",
    "# 5. Running Models Efficiently\n",
    "\n",
    "Optimize model inference for cloud environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This simulates model loading without actually loading large models\n",
    "class CloudModelSimulator:\n",
    "    \"\"\"Simulate running models in cloud with resource tracking\"\"\"\n",
    "    \n",
    "    MODEL_CONFIGS = {\n",
    "        \"tiny\": {\"size_gb\": 0.5, \"load_time\": 2, \"tokens_per_sec\": 50},\n",
    "        \"small\": {\"size_gb\": 2, \"load_time\": 5, \"tokens_per_sec\": 30},\n",
    "        \"medium\": {\"size_gb\": 7, \"load_time\": 15, \"tokens_per_sec\": 15},\n",
    "        \"large\": {\"size_gb\": 13, \"load_time\": 30, \"tokens_per_sec\": 8},\n",
    "        \"huge\": {\"size_gb\": 30, \"load_time\": 60, \"tokens_per_sec\": 3}\n",
    "    }\n",
    "    \n",
    "    def __init__(self, model_size=\"small\"):\n",
    "        if model_size not in self.MODEL_CONFIGS:\n",
    "            raise ValueError(f\"Unknown model size: {model_size}\")\n",
    "        \n",
    "        self.model_size = model_size\n",
    "        self.config = self.MODEL_CONFIGS[model_size]\n",
    "        self.loaded = False\n",
    "        self.total_tokens = 0\n",
    "        self.total_time = 0\n",
    "    \n",
    "    def load(self):\n",
    "        \"\"\"Simulate model loading\"\"\"\n",
    "        print(f\"Loading {self.model_size} model ({self.config['size_gb']}GB)...\")\n",
    "        \n",
    "        # Simulate loading with progress bar\n",
    "        load_steps = 10\n",
    "        for i in range(load_steps + 1):\n",
    "            progress = i / load_steps\n",
    "            bar = \"â–ˆ\" * int(progress * 30)\n",
    "            print(f\"\\r[{bar:<30}] {progress*100:.0f}%\", end=\"\")\n",
    "            time.sleep(self.config['load_time'] / load_steps / 10)  # Speed up for demo\n",
    "        \n",
    "        print(f\"\\nâœ… Model loaded in {self.config['load_time']}s (simulated)\")\n",
    "        self.loaded = True\n",
    "    \n",
    "    def generate(self, prompt, max_tokens=100):\n",
    "        \"\"\"Simulate text generation\"\"\"\n",
    "        if not self.loaded:\n",
    "            print(\"Error: Model not loaded. Call load() first.\")\n",
    "            return None\n",
    "        \n",
    "        # Calculate generation time\n",
    "        gen_time = max_tokens / self.config['tokens_per_sec']\n",
    "        \n",
    "        print(f\"\\nGenerating {max_tokens} tokens...\")\n",
    "        print(f\"Speed: {self.config['tokens_per_sec']} tokens/sec\")\n",
    "        \n",
    "        # Simulate generation with progress\n",
    "        for i in range(0, max_tokens, 10):\n",
    "            print(\".\", end=\"\", flush=True)\n",
    "            time.sleep(0.1)  # Simulate processing\n",
    "        \n",
    "        # Update stats\n",
    "        self.total_tokens += max_tokens\n",
    "        self.total_time += gen_time\n",
    "        \n",
    "        print(f\"\\nâœ… Generated in {gen_time:.2f}s (simulated)\")\n",
    "        return f\"[Generated text for prompt: '{prompt[:50]}...']\"  # Placeholder\n",
    "    \n",
    "    def estimate_cost(self, instance_type=\"e2-standard-4\"):\n",
    "        \"\"\"Estimate cost for running this model\"\"\"\n",
    "        instance_prices = {\n",
    "            \"e2-medium\": 0.027,\n",
    "            \"e2-standard-4\": 0.134,\n",
    "            \"n2-standard-8\": 0.388,\n",
    "            \"a2-highgpu-1g\": 2.95\n",
    "        }\n",
    "        \n",
    "        if instance_type not in instance_prices:\n",
    "            return None\n",
    "        \n",
    "        # Estimate based on model size\n",
    "        min_ram = self.config['size_gb'] * 2  # Rule of thumb: 2x model size\n",
    "        hourly_rate = instance_prices[instance_type]\n",
    "        \n",
    "        return {\n",
    "            \"model\": self.model_size,\n",
    "            \"min_ram_gb\": min_ram,\n",
    "            \"instance\": instance_type,\n",
    "            \"hourly_cost\": hourly_rate,\n",
    "            \"cost_per_1k_tokens\": (hourly_rate / 3600) * (1000 / self.config['tokens_per_sec'])\n",
    "        }\n",
    "\n",
    "# Test different model sizes\n",
    "print(\"Model Size Comparison\\n\" + \"=\"*50)\n",
    "\n",
    "for size in [\"tiny\", \"small\", \"medium\"]:\n",
    "    model = CloudModelSimulator(size)\n",
    "    cost_info = model.estimate_cost(\"e2-standard-4\")\n",
    "    \n",
    "    print(f\"\\n{size.upper()} Model:\")\n",
    "    print(f\"  Size: {model.config['size_gb']}GB\")\n",
    "    print(f\"  Speed: {model.config['tokens_per_sec']} tokens/sec\")\n",
    "    print(f\"  Min RAM: {cost_info['min_ram_gb']}GB\")\n",
    "    print(f\"  Cost per 1K tokens: ${cost_info['cost_per_1k_tokens']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate model usage\n",
    "print(\"Running Model Demo\\n\" + \"=\"*50)\n",
    "\n",
    "# Load and use a model\n",
    "model = CloudModelSimulator(\"small\")\n",
    "model.load()\n",
    "\n",
    "# Generate text\n",
    "prompts = [\n",
    "    \"Explain cloud computing\",\n",
    "    \"What is machine learning?\",\n",
    "    \"Benefits of remote work\"\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    result = model.generate(prompt, max_tokens=50)\n",
    "    print(f\"Result: {result}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='storage'></a>\n",
    "\n",
    "# 6. Cloud Storage Simulation\n",
    "\n",
    "Practice working with cloud storage patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudStorage:\n",
    "    \"\"\"Simulate cloud storage operations\"\"\"\n",
    "    \n",
    "    def __init__(self, bucket_name):\n",
    "        self.bucket_name = bucket_name\n",
    "        self.files = {}\n",
    "        self.total_size = 0\n",
    "        self.operations = []\n",
    "    \n",
    "    def upload(self, file_name, size_mb, file_type=\"data\"):\n",
    "        \"\"\"Upload file to bucket\"\"\"\n",
    "        print(f\"Uploading {file_name} ({size_mb}MB) to gs://{self.bucket_name}/\")\n",
    "        \n",
    "        # Simulate upload with progress\n",
    "        upload_time = size_mb / 10  # 10MB/s upload speed\n",
    "        print(f\"Upload time: {upload_time:.1f}s\")\n",
    "        \n",
    "        # Store file metadata\n",
    "        self.files[file_name] = {\n",
    "            \"size_mb\": size_mb,\n",
    "            \"type\": file_type,\n",
    "            \"uploaded\": datetime.now(),\n",
    "            \"url\": f\"gs://{self.bucket_name}/{file_name}\"\n",
    "        }\n",
    "        \n",
    "        self.total_size += size_mb\n",
    "        self.operations.append((\"upload\", file_name, size_mb))\n",
    "        \n",
    "        print(f\"âœ… Upload complete: {self.files[file_name]['url']}\")\n",
    "        return True\n",
    "    \n",
    "    def download(self, file_name):\n",
    "        \"\"\"Download file from bucket\"\"\"\n",
    "        if file_name not in self.files:\n",
    "            print(f\"Error: {file_name} not found in bucket\")\n",
    "            return False\n",
    "        \n",
    "        file_info = self.files[file_name]\n",
    "        print(f\"Downloading {file_name} ({file_info['size_mb']}MB)...\")\n",
    "        \n",
    "        download_time = file_info['size_mb'] / 20  # 20MB/s download\n",
    "        print(f\"Download time: {download_time:.1f}s\")\n",
    "        \n",
    "        self.operations.append((\"download\", file_name, file_info['size_mb']))\n",
    "        print(f\"âœ… Downloaded to ./{file_name}\")\n",
    "        return True\n",
    "    \n",
    "    def list_files(self):\n",
    "        \"\"\"List all files in bucket\"\"\"\n",
    "        print(f\"\\nFiles in gs://{self.bucket_name}/\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        if not self.files:\n",
    "            print(\"(empty)\")\n",
    "            return\n",
    "        \n",
    "        for name, info in self.files.items():\n",
    "            print(f\"{name:<30} {info['size_mb']:>8}MB  {info['type']:<10}\")\n",
    "        \n",
    "        print(\"-\" * 60)\n",
    "        print(f\"Total: {len(self.files)} files, {self.total_size}MB\")\n",
    "    \n",
    "    def estimate_monthly_cost(self):\n",
    "        \"\"\"Estimate storage costs\"\"\"\n",
    "        storage_cost = self.total_size * 0.02 / 1000  # $0.02 per GB\n",
    "        \n",
    "        # Calculate operation costs\n",
    "        operation_costs = {\n",
    "            \"upload\": sum(op[2] for op in self.operations if op[0] == \"upload\") * 0.005 / 1000,\n",
    "            \"download\": sum(op[2] for op in self.operations if op[0] == \"download\") * 0.12 / 1000\n",
    "        }\n",
    "        \n",
    "        total = storage_cost + sum(operation_costs.values())\n",
    "        \n",
    "        return {\n",
    "            \"storage\": storage_cost,\n",
    "            \"operations\": operation_costs,\n",
    "            \"total\": total\n",
    "        }\n",
    "\n",
    "# Create and use cloud storage\n",
    "storage = CloudStorage(\"research-data-2024\")\n",
    "\n",
    "# Upload files\n",
    "print(\"Cloud Storage Operations Demo\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "storage.upload(\"dataset.csv\", 500, \"data\")\n",
    "storage.upload(\"model_weights.pkl\", 2000, \"model\")\n",
    "storage.upload(\"results.json\", 10, \"output\")\n",
    "\n",
    "# List files\n",
    "storage.list_files()\n",
    "\n",
    "# Download a file\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "storage.download(\"model_weights.pkl\")\n",
    "\n",
    "# Calculate costs\n",
    "print(\"\\nMonthly Cost Estimate:\")\n",
    "costs = storage.estimate_monthly_cost()\n",
    "print(f\"  Storage: ${costs['storage']:.4f}\")\n",
    "print(f\"  Upload: ${costs['operations']['upload']:.4f}\")\n",
    "print(f\"  Download: ${costs['operations']['download']:.4f}\")\n",
    "print(f\"  Total: ${costs['total']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='benchmark'></a>\n",
    "\n",
    "# 7. Performance Benchmarking\n",
    "\n",
    "Compare local vs cloud performance for different tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_task(task_func, name, iterations=3):\n",
    "    \"\"\"Benchmark a computational task\"\"\"\n",
    "    times = []\n",
    "    \n",
    "    print(f\"Benchmarking: {name}\")\n",
    "    for i in range(iterations):\n",
    "        start = time.time()\n",
    "        result = task_func()\n",
    "        elapsed = time.time() - start\n",
    "        times.append(elapsed)\n",
    "        print(f\"  Run {i+1}: {elapsed:.3f}s\")\n",
    "    \n",
    "    avg_time = np.mean(times)\n",
    "    std_time = np.std(times)\n",
    "    \n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"avg_time\": avg_time,\n",
    "        \"std_time\": std_time,\n",
    "        \"times\": times\n",
    "    }\n",
    "\n",
    "# Define benchmark tasks\n",
    "def cpu_intensive_task():\n",
    "    \"\"\"CPU-intensive computation\"\"\"\n",
    "    # Matrix multiplication\n",
    "    size = 1000\n",
    "    A = np.random.rand(size, size)\n",
    "    B = np.random.rand(size, size)\n",
    "    C = np.dot(A, B)\n",
    "    return C.sum()\n",
    "\n",
    "def memory_intensive_task():\n",
    "    \"\"\"Memory-intensive task\"\"\"\n",
    "    # Large array operations\n",
    "    size = 10_000_000\n",
    "    arr = np.random.rand(size)\n",
    "    sorted_arr = np.sort(arr)\n",
    "    return sorted_arr[0]\n",
    "\n",
    "def io_intensive_task():\n",
    "    \"\"\"I/O-intensive task\"\"\"\n",
    "    # File operations (simulated)\n",
    "    data = \"x\" * 1_000_000  # 1MB of data\n",
    "    temp_file = \"temp_benchmark.txt\"\n",
    "    \n",
    "    # Write\n",
    "    with open(temp_file, 'w') as f:\n",
    "        for _ in range(10):\n",
    "            f.write(data)\n",
    "    \n",
    "    # Read\n",
    "    with open(temp_file, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Cleanup\n",
    "    os.remove(temp_file)\n",
    "    return len(content)\n",
    "\n",
    "# Run benchmarks\n",
    "print(\"Performance Benchmarks\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "benchmarks = [\n",
    "    benchmark_task(cpu_intensive_task, \"CPU Intensive (Matrix Mult)\", 3),\n",
    "    benchmark_task(memory_intensive_task, \"Memory Intensive (Array Sort)\", 3),\n",
    "    benchmark_task(io_intensive_task, \"I/O Intensive (File Ops)\", 3)\n",
    "]\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Benchmark Summary:\\n\")\n",
    "\n",
    "results_df = pd.DataFrame(benchmarks)\n",
    "results_df['avg_time'] = results_df['avg_time'].round(3)\n",
    "results_df['std_time'] = results_df['std_time'].round(3)\n",
    "\n",
    "print(results_df[['name', 'avg_time', 'std_time']].to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "names = [b['name'].split('(')[0].strip() for b in benchmarks]\n",
    "times = [b['avg_time'] for b in benchmarks]\n",
    "errors = [b['std_time'] for b in benchmarks]\n",
    "\n",
    "bars = plt.bar(names, times, yerr=errors, capsize=5)\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.title('Task Performance Benchmarks')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add value labels\n",
    "for bar, time in zip(bars, times):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "             f'{time:.3f}s', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Cloud vs Local Insights:\")\n",
    "print(\"- CPU tasks: Cloud wins with more cores\")\n",
    "print(\"- Memory tasks: Cloud wins with more RAM\")\n",
    "print(\"- I/O tasks: Depends on storage type (SSD vs HDD)\")\n",
    "print(\"- Network tasks: Local wins (no latency)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Exercise: Cloud Decision Matrix\n",
    "\n",
    "Help decide when to use cloud vs local computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cloud_decision_matrix(project_specs):\n",
    "    \"\"\"Evaluate whether to use cloud or local computing\"\"\"\n",
    "    \n",
    "    scores = {\"cloud\": 0, \"local\": 0}\n",
    "    recommendations = []\n",
    "    \n",
    "    # Evaluate each factor\n",
    "    if project_specs[\"data_size_gb\"] > 50:\n",
    "        scores[\"cloud\"] += 2\n",
    "        recommendations.append(\"Large data favors cloud storage\")\n",
    "    else:\n",
    "        scores[\"local\"] += 1\n",
    "        recommendations.append(\"Small data can be handled locally\")\n",
    "    \n",
    "    if project_specs[\"needs_gpu\"]:\n",
    "        scores[\"cloud\"] += 3\n",
    "        recommendations.append(\"GPU requirement strongly favors cloud\")\n",
    "    \n",
    "    if project_specs[\"team_size\"] > 1:\n",
    "        scores[\"cloud\"] += 2\n",
    "        recommendations.append(\"Team collaboration easier in cloud\")\n",
    "    else:\n",
    "        scores[\"local\"] += 1\n",
    "        recommendations.append(\"Solo work can be done locally\")\n",
    "    \n",
    "    if project_specs[\"duration_days\"] < 7:\n",
    "        scores[\"cloud\"] += 1\n",
    "        recommendations.append(\"Short projects benefit from cloud flexibility\")\n",
    "    else:\n",
    "        scores[\"local\"] += 1\n",
    "        recommendations.append(\"Long projects might be cheaper locally\")\n",
    "    \n",
    "    if project_specs[\"budget_usd\"] < 50:\n",
    "        scores[\"local\"] += 2\n",
    "        recommendations.append(\"Limited budget favors local computing\")\n",
    "    else:\n",
    "        scores[\"cloud\"] += 1\n",
    "        recommendations.append(\"Adequate budget allows cloud usage\")\n",
    "    \n",
    "    if project_specs[\"sensitive_data\"]:\n",
    "        scores[\"local\"] += 3\n",
    "        recommendations.append(\"Sensitive data may require local processing\")\n",
    "    \n",
    "    # Determine winner\n",
    "    if scores[\"cloud\"] > scores[\"local\"]:\n",
    "        decision = \"Use CLOUD Computing\"\n",
    "        color = \"green\"\n",
    "    elif scores[\"local\"] > scores[\"cloud\"]:\n",
    "        decision = \"Use LOCAL Computing\"\n",
    "        color = \"blue\"\n",
    "    else:\n",
    "        decision = \"Either option works\"\n",
    "        color = \"yellow\"\n",
    "    \n",
    "    return {\n",
    "        \"decision\": decision,\n",
    "        \"scores\": scores,\n",
    "        \"recommendations\": recommendations\n",
    "    }\n",
    "\n",
    "# Test with different scenarios\n",
    "scenarios = [\n",
    "    {\n",
    "        \"name\": \"Deep Learning Research\",\n",
    "        \"data_size_gb\": 100,\n",
    "        \"needs_gpu\": True,\n",
    "        \"team_size\": 3,\n",
    "        \"duration_days\": 30,\n",
    "        \"budget_usd\": 500,\n",
    "        \"sensitive_data\": False\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Personal Blog Analysis\",\n",
    "        \"data_size_gb\": 5,\n",
    "        \"needs_gpu\": False,\n",
    "        \"team_size\": 1,\n",
    "        \"duration_days\": 60,\n",
    "        \"budget_usd\": 20,\n",
    "        \"sensitive_data\": False\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Healthcare Data Study\",\n",
    "        \"data_size_gb\": 30,\n",
    "        \"needs_gpu\": False,\n",
    "        \"team_size\": 2,\n",
    "        \"duration_days\": 90,\n",
    "        \"budget_usd\": 200,\n",
    "        \"sensitive_data\": True\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Cloud vs Local Decision Matrix\\n\" + \"=\"*50)\n",
    "\n",
    "for scenario in scenarios:\n",
    "    print(f\"\\nðŸ“Š Project: {scenario['name']}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Display specs\n",
    "    print(\"Specifications:\")\n",
    "    for key, value in scenario.items():\n",
    "        if key != \"name\":\n",
    "            print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Get decision\n",
    "    result = cloud_decision_matrix(scenario)\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ Decision: {result['decision']}\")\n",
    "    print(f\"   Cloud Score: {result['scores']['cloud']}\")\n",
    "    print(f\"   Local Score: {result['scores']['local']}\")\n",
    "    \n",
    "    print(\"\\nRecommendations:\")\n",
    "    for rec in result['recommendations']:\n",
    "        print(f\"  â€¢ {rec}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Remember: These are guidelines. Consider your specific needs!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Cloud Concepts**: Understood VMs, serverless, and storage patterns\n",
    "2. **Cost Management**: Learned to estimate and optimize cloud costs\n",
    "3. **Remote Patterns**: Practiced SSH, file transfer, and job management\n",
    "4. **Performance**: Compared local vs cloud for different workloads\n",
    "5. **Decision Making**: Developed framework for cloud adoption choices\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Create a GCP account and claim your $300 credit\n",
    "2. Launch your first VM and run a Python script\n",
    "3. Practice with the cost calculator before starting projects\n",
    "4. Consider environmental impact in your cloud usage\n",
    "5. Document your setup for reproducibility\n",
    "\n",
    "### Resources for Practice\n",
    "\n",
    "- [Google Cloud Skills Boost](https://www.cloudskillsboost.google/)\n",
    "- [GCP Free Tier](https://cloud.google.com/free)\n",
    "- [Cloud Carbon Footprint](https://www.cloudcarbonfootprint.org/)\n",
    "- [GitHub Codespaces](https://github.com/features/codespaces)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}