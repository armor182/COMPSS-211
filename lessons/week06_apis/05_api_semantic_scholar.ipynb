{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Web APIs: Accessing Academic Literature with Semantic Scholar\n",
    "\n",
    "* * * \n",
    "\n",
    "### Icons used in this notebook\n",
    "üîî **Question**: A quick question to help you understand what's going on.<br>\n",
    "ü•ä **Challenge**: Interactive excercise. We'll work through these in the workshop!<br>\n",
    "‚ö†Ô∏è **Warning**: Heads-up about tricky stuff or common mistakes.<br>\n",
    "üí° **Tip**: How to do something a bit more efficiently or effectively.<br>\n",
    "üé¨ **Demo**: Showing off something more advanced ‚Äì so you know what Python can be used for!<br>\n",
    "\n",
    "### Learning Objectives\n",
    "1. [Introduction to Semantic Scholar API](#semantic)\n",
    "2. [Searching for Academic Papers](#search)\n",
    "3. [Author and Citation Analysis](#authors)\n",
    "4. [Research Trend Analysis](#trends)\n",
    "5. [Demo: Citation Network Analysis](#demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='semantic'></a>\n",
    "\n",
    "# Semantic Scholar API\n",
    "\n",
    "Semantic Scholar is a free, AI-powered research tool for scientific literature. It indexes millions of academic papers across various fields including computer science, medicine, biology, physics, and more. The API provides access to:\n",
    "\n",
    "- Paper metadata (titles, abstracts, authors, citations)\n",
    "- Author information and profiles\n",
    "- Citation graphs and academic relationships\n",
    "- Research trends and influential papers\n",
    "\n",
    "üí° **Tip**: The Semantic Scholar API is free and doesn't require an API key for basic usage, but they recommend getting one for higher rate limits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up API Access\n",
    "\n",
    "While an API key is optional, it's recommended for better rate limits. You can get one at:\n",
    "https://www.semanticscholar.org/product/api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "def get_semantic_scholar_key():\n",
    "    config_file_path = os.path.expanduser(\"~/.notebook-api-keys\")\n",
    "    config = configparser.ConfigParser(interpolation=None)\n",
    "    \n",
    "    if os.path.exists(config_file_path):\n",
    "        config.read(config_file_path)\n",
    "    \n",
    "    # Check if API key exists\n",
    "    if config.has_option(\"API_KEYS\", \"SEMANTIC_SCHOLAR\"):\n",
    "        update_key = input(\"Semantic Scholar API key found. Update it? (y/n): \").lower()\n",
    "        if update_key == 'n':\n",
    "            return config.get(\"API_KEYS\", \"SEMANTIC_SCHOLAR\")\n",
    "    \n",
    "    # Option to skip API key\n",
    "    use_key = input(\"Do you have a Semantic Scholar API key? (y/n): \").lower()\n",
    "    \n",
    "    if use_key == 'y':\n",
    "        api_key = getpass(\"Enter your Semantic Scholar API key: \")\n",
    "        \n",
    "        # Save the API key\n",
    "        if not config.has_section(\"API_KEYS\"):\n",
    "            config.add_section(\"API_KEYS\")\n",
    "        config.set(\"API_KEYS\", \"SEMANTIC_SCHOLAR\", api_key)\n",
    "        \n",
    "        with open(config_file_path, \"w\") as f:\n",
    "            config.write(f)\n",
    "        \n",
    "        return api_key\n",
    "    else:\n",
    "        print(\"No API key provided. Using free tier with lower rate limits.\")\n",
    "        return None\n",
    "\n",
    "# Get API key (optional)\n",
    "semantic_key = get_semantic_scholar_key()\n",
    "print(\"Semantic Scholar setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the API Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticScholarAPI:\n",
    "    def __init__(self, api_key=None):\n",
    "        self.base_url = \"https://api.semanticscholar.org/graph/v1\"\n",
    "        self.headers = {}\n",
    "        if api_key:\n",
    "            self.headers['x-api-key'] = api_key\n",
    "        \n",
    "        # Rate limiting\n",
    "        self.last_request = 0\n",
    "        self.min_interval = 1.0 if not api_key else 0.1  # Slower for free tier\n",
    "    \n",
    "    def _make_request(self, endpoint, params=None):\n",
    "        \"\"\"Make a rate-limited request to the API\"\"\"\n",
    "        # Rate limiting\n",
    "        elapsed = time.time() - self.last_request\n",
    "        if elapsed < self.min_interval:\n",
    "            time.sleep(self.min_interval - elapsed)\n",
    "        \n",
    "        url = f\"{self.base_url}/{endpoint}\"\n",
    "        response = requests.get(url, headers=self.headers, params=params)\n",
    "        self.last_request = time.time()\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Error {response.status_code}: {response.text}\")\n",
    "            return None\n",
    "    \n",
    "    def search_papers(self, query, limit=10, fields=None):\n",
    "        \"\"\"Search for papers by query\"\"\"\n",
    "        if fields is None:\n",
    "            fields = ['title', 'abstract', 'authors', 'year', 'citationCount', 'url', 'venue']\n",
    "        \n",
    "        params = {\n",
    "            'query': query,\n",
    "            'limit': limit,\n",
    "            'fields': ','.join(fields)\n",
    "        }\n",
    "        \n",
    "        return self._make_request('paper/search', params)\n",
    "    \n",
    "    def get_paper(self, paper_id, fields=None):\n",
    "        \"\"\"Get detailed information about a specific paper\"\"\"\n",
    "        if fields is None:\n",
    "            fields = ['title', 'abstract', 'authors', 'year', 'citationCount', 'referenceCount', 'citations', 'references']\n",
    "        \n",
    "        params = {'fields': ','.join(fields)}\n",
    "        return self._make_request(f'paper/{paper_id}', params)\n",
    "    \n",
    "    def get_author(self, author_id, fields=None):\n",
    "        \"\"\"Get information about an author\"\"\"\n",
    "        if fields is None:\n",
    "            fields = ['name', 'paperCount', 'citationCount', 'hIndex', 'papers']\n",
    "        \n",
    "        params = {'fields': ','.join(fields)}\n",
    "        return self._make_request(f'author/{author_id}', params)\n",
    "\n",
    "# Initialize the API client\n",
    "ss_api = SemanticScholarAPI(semantic_key)\n",
    "print(\"Semantic Scholar API client initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='search'></a>\n",
    "\n",
    "# Searching for Academic Papers\n",
    "\n",
    "Let's start by searching for papers on a specific topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for papers about machine learning\n",
    "ml_papers = ss_api.search_papers('machine learning', limit=20)\n",
    "\n",
    "if ml_papers and 'data' in ml_papers:\n",
    "    print(f\"Found {ml_papers['total']} papers about machine learning\")\n",
    "    print(f\"Retrieved {len(ml_papers['data'])} papers\")\n",
    "    \n",
    "    # Look at the first paper\n",
    "    first_paper = ml_papers['data'][0]\n",
    "    print(f\"\\nFirst paper:\")\n",
    "    print(f\"Title: {first_paper['title']}\")\n",
    "    print(f\"Year: {first_paper['year']}\")\n",
    "    print(f\"Citations: {first_paper['citationCount']}\")\n",
    "    print(f\"Authors: {[author['name'] for author in first_paper['authors'][:3]]}\")\n",
    "else:\n",
    "    print(\"No papers found or API error occurred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for easier analysis\n",
    "if ml_papers and 'data' in ml_papers:\n",
    "    papers_data = []\n",
    "    \n",
    "    for paper in ml_papers['data']:\n",
    "        papers_data.append({\n",
    "            'paperId': paper['paperId'],\n",
    "            'title': paper['title'],\n",
    "            'year': paper['year'],\n",
    "            'citationCount': paper['citationCount'],\n",
    "            'venue': paper.get('venue', 'Unknown'),\n",
    "            'abstract': paper.get('abstract', '')[:200] if paper.get('abstract') else '',\n",
    "            'num_authors': len(paper['authors']),\n",
    "            'first_author': paper['authors'][0]['name'] if paper['authors'] else 'Unknown'\n",
    "        })\n",
    "    \n",
    "    df_papers = pd.DataFrame(papers_data)\n",
    "    print(f\"Created DataFrame with {len(df_papers)} papers\")\n",
    "    df_papers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Paper Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics about the papers\n",
    "if not df_papers.empty:\n",
    "    print(\"Paper Statistics:\")\n",
    "    print(f\"Average citations: {df_papers['citationCount'].mean():.1f}\")\n",
    "    print(f\"Median citations: {df_papers['citationCount'].median():.1f}\")\n",
    "    print(f\"Year range: {df_papers['year'].min()} - {df_papers['year'].max()}\")\n",
    "    print(f\"Average authors per paper: {df_papers['num_authors'].mean():.1f}\")\n",
    "    \n",
    "    # Visualizations\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    df_papers['citationCount'].hist(bins=15, alpha=0.7)\n",
    "    plt.xlabel('Citation Count')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Citation Counts')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    df_papers['year'].hist(bins=15, alpha=0.7, color='orange')\n",
    "    plt.xlabel('Publication Year')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Papers by Publication Year')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    df_papers['num_authors'].hist(bins=10, alpha=0.7, color='green')\n",
    "    plt.xlabel('Number of Authors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Author Count')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Cited Papers and Venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_papers.empty:\n",
    "    # Top cited papers\n",
    "    print(\"Top 5 Most Cited Papers:\")\n",
    "    top_cited = df_papers.nlargest(5, 'citationCount')[['title', 'year', 'citationCount', 'first_author']]\n",
    "    for idx, row in top_cited.iterrows():\n",
    "        print(f\"{row['citationCount']} citations: {row['title'][:80]}... ({row['year']})\")\n",
    "    \n",
    "    print(\"\\nTop Venues:\")\n",
    "    venue_counts = df_papers['venue'].value_counts().head(10)\n",
    "    print(venue_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge: Compare Research Areas\n",
    "\n",
    "- Search for papers in 2-3 different research areas\n",
    "- Compare citation patterns, publication years, and author counts\n",
    "- Which field tends to have more citations? More collaborators?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='authors'></a>\n",
    "\n",
    "# Author and Citation Analysis\n",
    "\n",
    "Let's dive deeper into author information and citation networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Detailed Paper Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detailed information about the most cited paper\n",
    "if not df_papers.empty:\n",
    "    most_cited_id = df_papers.loc[df_papers['citationCount'].idxmax(), 'paperId']\n",
    "    print(f\"Getting details for paper ID: {most_cited_id}\")\n",
    "    \n",
    "    detailed_paper = ss_api.get_paper(most_cited_id)\n",
    "    \n",
    "    if detailed_paper:\n",
    "        print(f\"Title: {detailed_paper['title']}\")\n",
    "        print(f\"Citations: {detailed_paper['citationCount']}\")\n",
    "        print(f\"References: {detailed_paper['referenceCount']}\")\n",
    "        print(f\"Abstract: {detailed_paper.get('abstract', 'No abstract available')[:300]}...\")\n",
    "        \n",
    "        # Authors information\n",
    "        print(f\"\\nAuthors:\")\n",
    "        for author in detailed_paper['authors'][:5]:  # First 5 authors\n",
    "            print(f\"  - {author['name']} (ID: {author['authorId']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author Profile Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the first author of the most cited paper\n",
    "if detailed_paper and detailed_paper['authors']:\n",
    "    first_author_id = detailed_paper['authors'][0]['authorId']\n",
    "    \n",
    "    if first_author_id:\n",
    "        author_info = ss_api.get_author(first_author_id)\n",
    "        \n",
    "        if author_info:\n",
    "            print(f\"Author: {author_info['name']}\")\n",
    "            print(f\"Total papers: {author_info['paperCount']}\")\n",
    "            print(f\"Total citations: {author_info['citationCount']}\")\n",
    "            print(f\"h-index: {author_info['hIndex']}\")\n",
    "            \n",
    "            # Analyze their recent papers\n",
    "            if 'papers' in author_info and author_info['papers']:\n",
    "                recent_papers = author_info['papers'][:10]  # Last 10 papers\n",
    "                \n",
    "                years = [p['year'] for p in recent_papers if p['year']]\n",
    "                citations = [p['citationCount'] for p in recent_papers]\n",
    "                \n",
    "                plt.figure(figsize=(12, 4))\n",
    "                \n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.scatter(years, citations, alpha=0.7)\n",
    "                plt.xlabel('Publication Year')\n",
    "                plt.ylabel('Citation Count')\n",
    "                plt.title(f\"Recent Papers by {author_info['name']}\")\n",
    "                \n",
    "                plt.subplot(1, 2, 2)\n",
    "                year_counts = pd.Series(years).value_counts().sort_index()\n",
    "                year_counts.plot(kind='bar', alpha=0.7)\n",
    "                plt.xlabel('Year')\n",
    "                plt.ylabel('Number of Papers')\n",
    "                plt.title('Publications by Year')\n",
    "                plt.xticks(rotation=45)\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='trends'></a>\n",
    "\n",
    "# Research Trend Analysis\n",
    "\n",
    "Let's analyze how research topics have evolved over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_research_trends(topics, years_back=10):\n",
    "    \"\"\"Analyze research trends for multiple topics over time\"\"\"\n",
    "    current_year = datetime.now().year\n",
    "    start_year = current_year - years_back\n",
    "    \n",
    "    trend_data = []\n",
    "    \n",
    "    for topic in topics:\n",
    "        print(f\"Analyzing trend for: {topic}\")\n",
    "        \n",
    "        # Search for papers on this topic\n",
    "        papers = ss_api.search_papers(topic, limit=100)\n",
    "        \n",
    "        if papers and 'data' in papers:\n",
    "            for paper in papers['data']:\n",
    "                if paper['year'] and paper['year'] >= start_year:\n",
    "                    trend_data.append({\n",
    "                        'topic': topic,\n",
    "                        'year': paper['year'],\n",
    "                        'title': paper['title'],\n",
    "                        'citations': paper['citationCount'],\n",
    "                        'authors': len(paper['authors'])\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(trend_data)\n",
    "\n",
    "# Analyze trends for AI-related topics\n",
    "ai_topics = ['deep learning', 'neural networks', 'computer vision']\n",
    "trends_df = analyze_research_trends(ai_topics, years_back=8)\n",
    "\n",
    "print(f\"Collected trend data: {len(trends_df)} papers\")\n",
    "if not trends_df.empty:\n",
    "    trends_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize research trends\n",
    "if not trends_df.empty:\n",
    "    # Papers published by year and topic\n",
    "    yearly_counts = trends_df.groupby(['topic', 'year']).size().reset_index(name='count')\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot 1: Number of papers over time\n",
    "    plt.subplot(1, 3, 1)\n",
    "    for topic in ai_topics:\n",
    "        topic_data = yearly_counts[yearly_counts['topic'] == topic]\n",
    "        plt.plot(topic_data['year'], topic_data['count'], marker='o', label=topic, linewidth=2)\n",
    "    \n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Number of Papers')\n",
    "    plt.title('Research Output Trends')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Average citations by topic and year\n",
    "    plt.subplot(1, 3, 2)\n",
    "    avg_citations = trends_df.groupby(['topic', 'year'])['citations'].mean().reset_index()\n",
    "    \n",
    "    for topic in ai_topics:\n",
    "        topic_data = avg_citations[avg_citations['topic'] == topic]\n",
    "        plt.plot(topic_data['year'], topic_data['citations'], marker='s', label=topic, linewidth=2)\n",
    "    \n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Average Citations')\n",
    "    plt.title('Citation Trends by Topic')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Collaboration trends (average authors)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    avg_authors = trends_df.groupby(['topic', 'year'])['authors'].mean().reset_index()\n",
    "    \n",
    "    for topic in ai_topics:\n",
    "        topic_data = avg_authors[avg_authors['topic'] == topic]\n",
    "        plt.plot(topic_data['year'], topic_data['authors'], marker='^', label=topic, linewidth=2)\n",
    "    \n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Average Authors per Paper')\n",
    "    plt.title('Collaboration Trends')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\nTrend Summary:\")\n",
    "    summary = trends_df.groupby('topic').agg({\n",
    "        'citations': ['mean', 'median'],\n",
    "        'authors': 'mean',\n",
    "        'year': ['min', 'max']\n",
    "    }).round(2)\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='demo'></a>\n",
    "\n",
    "# üé¨ Demo: Citation Network Analysis\n",
    "\n",
    "Let's explore the citation network around a highly cited paper to understand academic influence and connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_citation_network(paper_id, max_citations=10, max_references=10):\n",
    "    \"\"\"Build a citation network around a paper\"\"\"\n",
    "    print(f\"Building citation network for paper: {paper_id}\")\n",
    "    \n",
    "    # Get the main paper with citations and references\n",
    "    fields = ['title', 'year', 'citationCount', 'citations.title', 'citations.year', \n",
    "              'citations.citationCount', 'references.title', 'references.year', 'references.citationCount']\n",
    "    \n",
    "    paper = ss_api.get_paper(paper_id, fields)\n",
    "    \n",
    "    if not paper:\n",
    "        return None\n",
    "    \n",
    "    network_data = {\n",
    "        'main_paper': {\n",
    "            'id': paper_id,\n",
    "            'title': paper['title'],\n",
    "            'year': paper['year'],\n",
    "            'citations': paper['citationCount']\n",
    "        },\n",
    "        'citing_papers': [],\n",
    "        'referenced_papers': []\n",
    "    }\n",
    "    \n",
    "    # Process citing papers (papers that cite this one)\n",
    "    if 'citations' in paper and paper['citations']:\n",
    "        for citation in paper['citations'][:max_citations]:\n",
    "            network_data['citing_papers'].append({\n",
    "                'title': citation.get('title', 'No title'),\n",
    "                'year': citation.get('year', None),\n",
    "                'citations': citation.get('citationCount', 0)\n",
    "            })\n",
    "    \n",
    "    # Process referenced papers (papers this one cites)\n",
    "    if 'references' in paper and paper['references']:\n",
    "        for reference in paper['references'][:max_references]:\n",
    "            network_data['referenced_papers'].append({\n",
    "                'title': reference.get('title', 'No title'),\n",
    "                'year': reference.get('year', None),\n",
    "                'citations': reference.get('citationCount', 0)\n",
    "            })\n",
    "    \n",
    "    return network_data\n",
    "\n",
    "# Build citation network for the most cited paper from our earlier search\n",
    "if not df_papers.empty:\n",
    "    target_paper_id = df_papers.loc[df_papers['citationCount'].idxmax(), 'paperId']\n",
    "    citation_network = build_citation_network(target_paper_id)\n",
    "    \n",
    "    if citation_network:\n",
    "        print(f\"Citation network for: {citation_network['main_paper']['title'][:60]}...\")\n",
    "        print(f\"Main paper citations: {citation_network['main_paper']['citations']}\")\n",
    "        print(f\"Papers citing this one: {len(citation_network['citing_papers'])}\")\n",
    "        print(f\"Papers referenced by this one: {len(citation_network['referenced_papers'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the citation network\n",
    "if citation_network:\n",
    "    # Create DataFrames for analysis\n",
    "    citing_df = pd.DataFrame(citation_network['citing_papers'])\n",
    "    referenced_df = pd.DataFrame(citation_network['referenced_papers'])\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1: Citations over time for citing papers\n",
    "    plt.subplot(2, 3, 1)\n",
    "    if not citing_df.empty and 'year' in citing_df.columns:\n",
    "        citing_df = citing_df.dropna(subset=['year'])\n",
    "        if not citing_df.empty:\n",
    "            plt.scatter(citing_df['year'], citing_df['citations'], alpha=0.7, color='red')\n",
    "            plt.xlabel('Publication Year')\n",
    "            plt.ylabel('Citation Count')\n",
    "            plt.title('Papers Citing This Work')\n",
    "    \n",
    "    # Plot 2: Citations over time for referenced papers\n",
    "    plt.subplot(2, 3, 2)\n",
    "    if not referenced_df.empty and 'year' in referenced_df.columns:\n",
    "        referenced_df = referenced_df.dropna(subset=['year'])\n",
    "        if not referenced_df.empty:\n",
    "            plt.scatter(referenced_df['year'], referenced_df['citations'], alpha=0.7, color='blue')\n",
    "            plt.xlabel('Publication Year')\n",
    "            plt.ylabel('Citation Count')\n",
    "            plt.title('Papers Referenced by This Work')\n",
    "    \n",
    "    # Plot 3: Distribution of citation counts\n",
    "    plt.subplot(2, 3, 3)\n",
    "    all_citations = []\n",
    "    labels = []\n",
    "    \n",
    "    if not citing_df.empty:\n",
    "        all_citations.extend(citing_df['citations'].tolist())\n",
    "        labels.extend(['Citing'] * len(citing_df))\n",
    "    \n",
    "    if not referenced_df.empty:\n",
    "        all_citations.extend(referenced_df['citations'].tolist())\n",
    "        labels.extend(['Referenced'] * len(referenced_df))\n",
    "    \n",
    "    if all_citations:\n",
    "        citation_df = pd.DataFrame({'citations': all_citations, 'type': labels})\n",
    "        citation_df.boxplot(column='citations', by='type', ax=plt.gca())\n",
    "        plt.title('Citation Distribution Comparison')\n",
    "        plt.suptitle('')  # Remove automatic title\n",
    "    \n",
    "    # Plot 4: Timeline of citing papers\n",
    "    plt.subplot(2, 3, 4)\n",
    "    if not citing_df.empty and 'year' in citing_df.columns:\n",
    "        citing_df = citing_df.dropna(subset=['year'])\n",
    "        if not citing_df.empty:\n",
    "            year_counts = citing_df['year'].value_counts().sort_index()\n",
    "            year_counts.plot(kind='bar', alpha=0.7, color='red')\n",
    "            plt.xlabel('Year')\n",
    "            plt.ylabel('Number of Citing Papers')\n",
    "            plt.title('Citation Timeline')\n",
    "            plt.xticks(rotation=45)\n",
    "    \n",
    "    # Plot 5: Top citing papers\n",
    "    plt.subplot(2, 3, 5)\n",
    "    if not citing_df.empty:\n",
    "        top_citing = citing_df.nlargest(5, 'citations')\n",
    "        titles = [title[:20] + '...' for title in top_citing['title']]\n",
    "        plt.barh(range(len(titles)), top_citing['citations'], alpha=0.7, color='red')\n",
    "        plt.yticks(range(len(titles)), titles)\n",
    "        plt.xlabel('Citation Count')\n",
    "        plt.title('Most Cited Papers That Cite This Work')\n",
    "    \n",
    "    # Plot 6: Top referenced papers\n",
    "    plt.subplot(2, 3, 6)\n",
    "    if not referenced_df.empty:\n",
    "        top_referenced = referenced_df.nlargest(5, 'citations')\n",
    "        titles = [title[:20] + '...' for title in top_referenced['title']]\n",
    "        plt.barh(range(len(titles)), top_referenced['citations'], alpha=0.7, color='blue')\n",
    "        plt.yticks(range(len(titles)), titles)\n",
    "        plt.xlabel('Citation Count')\n",
    "        plt.title('Most Cited Referenced Papers')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print network statistics\n",
    "    print(\"\\nCitation Network Analysis:\")\n",
    "    if not citing_df.empty:\n",
    "        print(f\"Average citations of citing papers: {citing_df['citations'].mean():.1f}\")\n",
    "        print(f\"Most cited citing paper: {citing_df['citations'].max()} citations\")\n",
    "    \n",
    "    if not referenced_df.empty:\n",
    "        print(f\"Average citations of referenced papers: {referenced_df['citations'].mean():.1f}\")\n",
    "        print(f\"Most cited referenced paper: {referenced_df['citations'].max()} citations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting Data for Your Final Project\n",
    "\n",
    "Here's a comprehensive template for collecting academic literature data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_research_data(topics, papers_per_topic=50, include_authors=False, include_citations=False):\n",
    "    \"\"\"Collect comprehensive research data for analysis\"\"\"\n",
    "    all_papers = []\n",
    "    all_authors = []\n",
    "    all_citations = []\n",
    "    \n",
    "    for topic in topics:\n",
    "        print(f\"Collecting papers for: {topic}\")\n",
    "        \n",
    "        # Search for papers\n",
    "        papers = ss_api.search_papers(topic, limit=papers_per_topic)\n",
    "        \n",
    "        if papers and 'data' in papers:\n",
    "            for paper in papers['data']:\n",
    "                paper_data = {\n",
    "                    'paperId': paper['paperId'],\n",
    "                    'topic_search': topic,\n",
    "                    'title': paper['title'],\n",
    "                    'year': paper['year'],\n",
    "                    'citationCount': paper['citationCount'],\n",
    "                    'venue': paper.get('venue', ''),\n",
    "                    'abstract': paper.get('abstract', ''),\n",
    "                    'num_authors': len(paper['authors']),\n",
    "                    'url': paper.get('url', '')\n",
    "                }\n",
    "                all_papers.append(paper_data)\n",
    "                \n",
    "                # Collect author information if requested\n",
    "                if include_authors:\n",
    "                    for author in paper['authors']:\n",
    "                        all_authors.append({\n",
    "                            'paperId': paper['paperId'],\n",
    "                            'authorId': author['authorId'],\n",
    "                            'name': author['name'],\n",
    "                            'topic_search': topic\n",
    "                        })\n",
    "                \n",
    "                # Get detailed citation info if requested (warning: slow!)\n",
    "                if include_citations and paper['citationCount'] > 10:\n",
    "                    detailed = ss_api.get_paper(paper['paperId'])\n",
    "                    if detailed and 'citations' in detailed:\n",
    "                        for citation in detailed['citations'][:5]:  # Top 5 citations\n",
    "                            all_citations.append({\n",
    "                                'cited_paper_id': paper['paperId'],\n",
    "                                'citing_paper_title': citation.get('title', ''),\n",
    "                                'citing_paper_year': citation.get('year', None),\n",
    "                                'topic_search': topic\n",
    "                            })\n",
    "        \n",
    "        print(f\"  Collected {len([p for p in all_papers if p['topic_search'] == topic])} papers\")\n",
    "    \n",
    "    # Convert to DataFrames\n",
    "    df_papers = pd.DataFrame(all_papers)\n",
    "    df_authors = pd.DataFrame(all_authors) if all_authors else None\n",
    "    df_citations = pd.DataFrame(all_citations) if all_citations else None\n",
    "    \n",
    "    return df_papers, df_authors, df_citations\n",
    "\n",
    "# Example usage for final project\n",
    "# research_topics = ['natural language processing', 'computer vision', 'robotics']\n",
    "# papers_df, authors_df, citations_df = collect_research_data(\n",
    "#     research_topics, \n",
    "#     papers_per_topic=30, \n",
    "#     include_authors=True\n",
    "# )\n",
    "# \n",
    "# # Save the data\n",
    "# papers_df.to_csv('research_papers.csv', index=False)\n",
    "# if authors_df is not None:\n",
    "#     authors_df.to_csv('research_authors.csv', index=False)\n",
    "# \n",
    "# print(f\"Final dataset: {len(papers_df)} papers from {len(research_topics)} topics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "## ‚ùó Key Points\n",
    "\n",
    "* Semantic Scholar API provides access to millions of academic papers across multiple disciplines\n",
    "* You can search by keywords, get detailed paper information, and analyze citation networks\n",
    "* Author profiles include metrics like h-index, total citations, and publication history\n",
    "* Citation networks reveal academic influence and research connections\n",
    "* Research trend analysis can show how fields evolve over time\n",
    "* The API is free but rate-limited; consider getting an API key for larger projects\n",
    "* Academic data is excellent for bibliometric analysis, research impact studies, and trend identification\n",
    "* Be mindful of rate limits when collecting large datasets\n",
    "  \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}