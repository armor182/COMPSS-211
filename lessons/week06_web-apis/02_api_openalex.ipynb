{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Web APIs: Exploring Academic Research with OpenAlex\n",
    "\n",
    "* * * \n",
    "\n",
    "### Icons used in this notebook\n",
    "üîî **Question**: A quick question to help you understand what's going on.<br>\n",
    "ü•ä **Challenge**: Interactive exercise. We'll work through these in the workshop!<br>\n",
    "‚ö†Ô∏è **Warning**: Heads-up about tricky stuff or common mistakes.<br>\n",
    "üí° **Tip**: How to do something a bit more efficiently or effectively.<br>\n",
    "üé¨ **Demo**: Showing off something more advanced ‚Äì so you know what Python can be used for!<br>\n",
    "\n",
    "### Learning Objectives\n",
    "1. [Introduction to OpenAlex](#1)\n",
    "2. [Setting up the OpenAlex API](#2)\n",
    "3. [Exploring Academic Works (Publications)](#3)\n",
    "4. [Analyzing Authors](#4)\n",
    "5. [Analyzing Institutions](#5)\n",
    "6. [Creating a Research Summary Function](#6)\n",
    "7. [Open Access Analysis](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "\n",
    "## Import Required Libraries\n",
    "\n",
    "Let's start by importing all the libraries we'll need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install trafilatura\n",
    "# !pip install PyMuPDF  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries for making web requests\n",
    "import requests\n",
    "import io\n",
    "import json\n",
    "import trafilatura # boilerplate removal tool for web pages\n",
    "import fitz  # PyMuPDF: fast, lightweight PDF parser\n",
    "\n",
    "# Data analysis libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Utility libraries\n",
    "from datetime import datetime\n",
    "import time\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to OpenAlex\n",
    "\n",
    "OpenAlex is a **free** and **open** catalog of the global research system. You can find metadata on individual articles, and explore how they connect to each other, who is producing them, and how ideas flow across time, disciplines, and places.\n",
    "\n",
    "### Why use OpenAlex?\n",
    "- **240+ million works** from all academic disciplines\n",
    "- **Completely free** - no API key required!\n",
    "- **Global coverage** - includes non-English research\n",
    "- **Rich metadata** - citations, authors, institutions, topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "\n",
    "## 2. Setting up the OpenAlex API\n",
    "\n",
    "First, let's set up our basic configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your email (recommended for polite requests)\n",
    "EMAIL = \"your-email@example.com\"  # Replace with your actual email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL for OpenAlex API\n",
    "BASE_URL = \"https://api.openalex.org\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Helper Function\n",
    "\n",
    "This function will make it easier to send requests to OpenAlex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_openalex_request(endpoint, params=None):\n",
    "    \"\"\"Make a request to OpenAlex API with proper headers.\"\"\"\n",
    "    if params is None:\n",
    "        params = {}\n",
    "    \n",
    "    # Add email to params for polite requests\n",
    "    params['mailto'] = EMAIL\n",
    "    \n",
    "    # Build the full URL\n",
    "    url = f\"{BASE_URL}/{endpoint}\"\n",
    "    \n",
    "    # Make the request\n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    # Check if successful\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Connection\n",
    "\n",
    "Let's make sure our connection works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get meta information about OpenAlex\n",
    "meta_info = make_openalex_request(\"works\", params={'per-page': 1})\n",
    "meta_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the total number of works\n",
    "meta_info['meta']['count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "\n",
    "## 3. Searching for Academic Works\n",
    "\n",
    "Works are the central entity in OpenAlex - they represent scholarly documents like journal articles, books, and dissertations.\n",
    "\n",
    "### Basic Search\n",
    "\n",
    "Let's search for research on \"social media\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our search parameters\n",
    "search_params = {\n",
    "    'search': 'social media',\n",
    "    'per-page': 5  # Get only 5 results to keep it simple\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the search request\n",
    "search_results = make_openalex_request('works', params=search_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display total count\n",
    "if search_results:\n",
    "    print(f\"Found {search_results['meta']['count']:,} works on 'social media'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Search Results\n",
    "\n",
    "Let's look at the titles of what we found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the titles\n",
    "print(\"\\nTop 5 results:\")\n",
    "\n",
    "for i, work in enumerate(search_results['results'], 1):\n",
    "    print(f\"\\n{i}. {work['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add More Filters\n",
    "\n",
    "Let's refine our search to get recent, highly-cited papers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for recent, highly-cited papers\n",
    "refined_params = {\n",
    "    'search': 'social media polarization',\n",
    "    'filter': 'from_publication_date:2020-01-01',  # Recent works only\n",
    "    'per-page': 10,\n",
    "    'sort': 'cited_by_count:desc'  # Sort by most cited\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the refined search\n",
    "refined_results = make_openalex_request('works', params=refined_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results with more details\n",
    "print(f\"Found {refined_results['meta']['count']:,} works on social media polarization since 2020\")\n",
    "print(\"\\nTop 3 results:\")\n",
    "\n",
    "for i, work in enumerate(refined_results['results'][:3], 1):\n",
    "    print(f\"\\n{i}. {work['title']}\")\n",
    "    print(f\"   Year: {work['publication_year']}\")\n",
    "    print(f\"   Citations: {work['cited_by_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining a Single Work in Detail\n",
    "\n",
    "Let's look at more details about the most cited paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most cited work\n",
    "if refined_results and refined_results['results']:\n",
    "    top_work = refined_results['results'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the title and basic info\n",
    "print(f\"Title: {top_work['title']}\")\n",
    "print(f\"Year: {top_work['publication_year']}\")\n",
    "print(f\"Type: {top_work['type']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display authors\n",
    "print(\"\\nAuthors:\")\n",
    "for authorship in top_work['authorships'][:3]:  # Show first 3 authors\n",
    "    author_name = authorship['author']['display_name']\n",
    "    print(f\"  - {author_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display impact metrics\n",
    "print(f\"\\nImpact Metrics:\")\n",
    "print(f\"  Citations: {top_work['cited_by_count']}\")\n",
    "print(f\"  Open Access: {'Yes' if top_work['open_access']['is_oa'] else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge 1: Search for Your Topic\n",
    "\n",
    "Try searching for a topic that interests you. Find:\n",
    "1. Total number of papers\n",
    "2. The most cited paper's title and citation count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Hint: Use the search parameters we learned above\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "\n",
    "## 4. Analyzing Authors\n",
    "\n",
    "OpenAlex tracks millions of authors. Let's explore author data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for authors in a field\n",
    "author_params = {\n",
    "    'search': 'machine learning',\n",
    "    'per-page': 5,\n",
    "    'sort': 'cited_by_count:desc'  # Get most cited authors\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the authors\n",
    "top_authors = make_openalex_request('authors', params=author_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display author information\n",
    "print(\"Top Authors in Machine Learning\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for author in top_authors['results']:\n",
    "    print(f\"\\nName: {author['display_name']}\")\n",
    "    print(f\"  Works: {author['works_count']:,}\")\n",
    "    print(f\"  Citations: {author['cited_by_count']:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Simple Author Table\n",
    "\n",
    "Let's organize this data in a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect author data\n",
    "authors_data = []\n",
    "for author in top_authors['results']:\n",
    "    authors_data.append({\n",
    "        'Name': author['display_name'],\n",
    "        'Works': author['works_count'],\n",
    "        'Citations': author['cited_by_count']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and display DataFrame\n",
    "authors_df = pd.DataFrame(authors_data)\n",
    "display(authors_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "\n",
    "## 5. Analyzing Institutions\n",
    "\n",
    "Let's look at research institutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top institutions\n",
    "inst_params = {\n",
    "    'filter': 'type:education',  # Only educational institutions\n",
    "    'per-page': 10,\n",
    "    'sort': 'works_count:desc'  # Sort by number of publications\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the request\n",
    "top_institutions = make_openalex_request('institutions', params=inst_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top 5 institutions\n",
    "print(\"Top Research Institutions by Output\")\n",
    "\n",
    "for i, inst in enumerate(top_institutions['results'][:5], 1):\n",
    "    print(f\"\\n{i}. {inst['display_name']}\")\n",
    "    print(f\"   Country: {inst.get('country_code', 'Unknown')}\")\n",
    "    print(f\"   Total Works: {inst['works_count']:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Trends Over Time\n",
    "\n",
    "Let's track how a research topic has grown over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the topic and years to analyze\n",
    "topic = \"artificial intelligence\"\n",
    "years = [2019, 2020, 2021, 2022, 2023, 2024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect publication counts for each year\n",
    "counts = []\n",
    "\n",
    "for year in years:\n",
    "    params = {\n",
    "        'search': topic,\n",
    "        'filter': f'publication_year:{year}',\n",
    "        'per-page': 1\n",
    "    }\n",
    "    result = make_openalex_request('works', params=params)\n",
    "    \n",
    "    if result:\n",
    "        counts.append(result['meta']['count'])\n",
    "    else:\n",
    "        counts.append(0)\n",
    "    \n",
    "    # Be polite to the API\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the counts\n",
    "print(f\"Publications on '{topic}' by year:\")\n",
    "for year, count in zip(years, counts):\n",
    "    print(f\"  {year}: {count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(years, counts, color='steelblue', edgecolor='black')\n",
    "plt.title(f\"Research Trend: {topic.title()}\")\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Publications')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Multiple Topics\n",
    "\n",
    "Let's compare trends for different topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define topics to compare\n",
    "topics_to_compare = [\n",
    "    \"machine learning\",\n",
    "    \"climate change\",\n",
    "    \"social media\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Years to analyze\n",
    "years = [2020, 2021, 2022, 2023]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect data for all topics\n",
    "trends_data = {}\n",
    "\n",
    "for topic in topics_to_compare:\n",
    "    topic_counts = []\n",
    "    \n",
    "    for year in years:\n",
    "        params = {\n",
    "            'search': topic,\n",
    "            'filter': f'publication_year:{year}',\n",
    "            'per-page': 1\n",
    "        }\n",
    "        result = make_openalex_request('works', params=params)\n",
    "        \n",
    "        if result:\n",
    "            topic_counts.append(result['meta']['count'])\n",
    "        else:\n",
    "            topic_counts.append(0)\n",
    "        \n",
    "        time.sleep(0.1)  # Be polite\n",
    "    \n",
    "    trends_data[topic] = topic_counts\n",
    "    print(f\"Collected data for: {topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for topic, counts in trends_data.items():\n",
    "    plt.plot(years, counts, marker='o', linewidth=2, label=topic.title())\n",
    "\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Publications')\n",
    "plt.title('Research Trends Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge 2: Complete Analysis\n",
    "\n",
    "Pick a research topic and create a complete analysis:\n",
    "1. Find the total number of papers\n",
    "2. Find the top author in this field\n",
    "3. Plot the trend over the last 3 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Start by defining your topic\n",
    "my_topic = \"your topic here\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6'></a>\n",
    "\n",
    "## 6. Creating a Research Summary Function\n",
    "\n",
    "Let's create a function that summarizes any research topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_summary(topic):\n",
    "    \"\"\"Create a summary of research on a topic.\"\"\"\n",
    "    \n",
    "    print(f\"\\nüìä RESEARCH SUMMARY: {topic.upper()}\")\n",
    "    \n",
    "    # Get total publications\n",
    "    params = {\n",
    "        'search': topic,\n",
    "        'per-page': 1\n",
    "    }\n",
    "    result = make_openalex_request('works', params=params)\n",
    "    \n",
    "    if result:\n",
    "        total = result['meta']['count']\n",
    "        print(f\"Total publications: {total:,}\")\n",
    "    \n",
    "    # Get recent publications\n",
    "    params['filter'] = 'from_publication_date:2023-01-01'\n",
    "    recent = make_openalex_request('works', params=params)\n",
    "    \n",
    "    if recent:\n",
    "        recent_count = recent['meta']['count']\n",
    "        print(f\"Publications since 2023: {recent_count:,}\")\n",
    "    \n",
    "    # Get top cited paper\n",
    "    params = {\n",
    "        'search': topic,\n",
    "        'sort': 'cited_by_count:desc',\n",
    "        'per-page': 1\n",
    "    }\n",
    "    top_paper = make_openalex_request('works', params=params)\n",
    "    \n",
    "    if top_paper and top_paper['results']:\n",
    "        paper = top_paper['results'][0]\n",
    "        print(f\"\\nMost cited paper:\")\n",
    "        print(f\"  Title: {paper['title'][:60]}...\")\n",
    "        print(f\"  Citations: {paper['cited_by_count']:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function\n",
    "research_summary(\"quantum computing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try another topic\n",
    "research_summary(\"deep learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7'></a>\n",
    "\n",
    "## 7. Open Access Analysis\n",
    "\n",
    "So far we‚Äôve looked at how OpenAlex gives us **metadata** (titles, authors, DOIs, etc.).  \n",
    "But OpenAlex also tells us where to find the **full text** of open-access papers.  \n",
    "\n",
    "The goal is to show how you can move from *metadata* ‚Üí *full text* ‚Üí *analysis* with only a few lines of code.\n",
    "\n",
    "Let's first analyze what percentage of papers are open access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"data science\"\n",
    "\n",
    "def count(filter_extra=\"\"):\n",
    "    params = {\n",
    "        \"search\": topic,\n",
    "        \"filter\": f\"from_publication_date:2023-01-01{filter_extra}\",\n",
    "        \"per-page\": 1\n",
    "    }\n",
    "    return requests.get(f\"{BASE_URL}/works\", params=params).json()[\"meta\"][\"count\"]\n",
    "\n",
    "total = count()\n",
    "oa = count(\",is_oa:true\")\n",
    "pct = (oa / total) * 100 if total else 0\n",
    "\n",
    "print(f\"Analysis for '{topic}' (2023‚Äìpresent):\")\n",
    "print(f\"  Total papers: {total:,}\")\n",
    "print(f\"  Open Access papers: {oa:,}\")\n",
    "print(f\"  Open Access percentage: {pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's build a tiny pipeline to:\n",
    "\n",
    "1. **Search** OpenAlex for recent open-access works on a topic (e.g., *machine learning*)\n",
    "2. **Pick** a PDF link from the metadata\n",
    "3. **Download** the PDF and **extract plain text** from it\n",
    "4. **Repeat** this process for a few papers, to show how you could scale up\n",
    "\n",
    "Note that we're simplifying things here. The code only looks for PDFs (not HTML), stops after a few papers, and our text extraction is lightweight (no formatting, just collapsed whitespace)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_oa_works(topic, from_date=\"2023-01-01\", per_page=50):\n",
    "    \"\"\"\n",
    "    Query OpenAlex for works on a given topic.\n",
    "    - topic: search string (e.g. \"machine learning\")\n",
    "    - from_date: only get works published after this date\n",
    "    - per_page: number of results to fetch (max 200)\n",
    "    \"\"\"\n",
    "    url = f\"{BASE_URL}/works\"\n",
    "    params = {\n",
    "        \"search\": topic,\n",
    "        \"filter\": f\"from_publication_date:{from_date},is_oa:true\",  # only open access\n",
    "        \"per_page\": per_page,\n",
    "    }\n",
    "    r = requests.get(url, params=params, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    return r.json()[\"results\"]\n",
    "\n",
    "def pick_pdf_url(work):\n",
    "    \"\"\"\n",
    "    Try to find a direct PDF link in the work metadata.\n",
    "    Checks best_oa_location first, then the generic open_access field.\n",
    "    Returns None if no PDF-looking URL is found.\n",
    "    \"\"\"\n",
    "    bol = work.get(\"best_oa_location\") or {}\n",
    "    candidates = [bol.get(\"url_for_pdf\"), bol.get(\"url\")]\n",
    "    oa = (work.get(\"open_access\") or {}).get(\"oa_url\")\n",
    "    if oa: \n",
    "        candidates.append(oa)\n",
    "    for u in candidates:\n",
    "        if u and u.lower().split(\"?\", 1)[0].endswith(\".pdf\"):\n",
    "            return u\n",
    "    return None\n",
    "\n",
    "def pdf_to_text(url):\n",
    "    \"\"\"\n",
    "    Download a PDF from the given URL and extract its text.\n",
    "    Uses PyMuPDF (fitz) for reliable PDF parsing.\n",
    "    Then collapses extra whitespace into single spaces.\n",
    "    \"\"\"\n",
    "    r = requests.get(url, headers={\"User-Agent\": \"OpenAlex-demo\"}, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    with io.BytesIO(r.content) as buf, fitz.open(stream=buf, filetype=\"pdf\") as doc:\n",
    "        raw = \"\\n\".join(p.get_text() for p in doc)\n",
    "    return \" \".join(raw.split())\n",
    "\n",
    "def harvest_texts(topic, k=5, from_date=\"2023-01-01\", per_page=100):\n",
    "    \"\"\"\n",
    "    Collect up to k open-access PDFs for a given topic and return their text.\n",
    "    - topic: what to search for in OpenAlex\n",
    "    - k: how many papers you want\n",
    "    - from_date: publication cutoff\n",
    "    - per_page: how many results to request per API call\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for w in search_oa_works(topic, from_date=from_date, per_page=per_page):\n",
    "        if len(out) >= k:  # stop once we have enough\n",
    "            break\n",
    "        pdf = pick_pdf_url(w)\n",
    "        if not pdf:\n",
    "            continue\n",
    "        try:\n",
    "            text = pdf_to_text(pdf)\n",
    "            if not text:\n",
    "                continue\n",
    "            out.append({\n",
    "                \"title\": w.get(\"title\"),\n",
    "                \"pdf_url\": pdf,\n",
    "                \"text\": text,\n",
    "            })\n",
    "        except Exception:\n",
    "            # keep it simple: skip any failures and move on\n",
    "            continue\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab 3 recent machine learning papers and preview their text\n",
    "results = harvest_texts(topic=\"machine learning\", k=3, from_date=\"2023-01-01\")\n",
    "for i, r in enumerate(results, 1):\n",
    "    print(f\"{i}. {r['title']}\")\n",
    "    print(r[\"pdf_url\"])\n",
    "    print(r[\"text\"][:500], \"\\n\")  # preview first 500 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### What we learned:\n",
    "\n",
    "1. **OpenAlex basics**\n",
    "   - Free API with no key required\n",
    "   - Access to 240+ million scholarly works\n",
    "\n",
    "2. **Core entities**\n",
    "   - Works (publications)\n",
    "   - Authors\n",
    "   - Institutions\n",
    "   - Topics\n",
    "\n",
    "3. **Key API parameters**\n",
    "   - `search`: Find content by keywords\n",
    "   - `filter`: Apply specific criteria\n",
    "   - `sort`: Order results\n",
    "   - `per-page`: Control result size\n",
    "\n",
    "4. **Analysis possibilities**\n",
    "   - Track research trends\n",
    "   - Analyze citation impact\n",
    "   - Study collaboration networks\n",
    "   - Monitor open access adoption\n",
    "   - Download and read open access papers\n",
    "\n",
    "### Next steps:\n",
    "- Explore other filters (institution, country, funding)\n",
    "- Build collaboration networks\n",
    "- Create citation analysis tools\n",
    "- Track emerging research areas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Tips for Using OpenAlex\n",
    "\n",
    "1. **Be polite**: Include your email and add delays between requests\n",
    "2. **Use filters**: They make your searches much more efficient\n",
    "3. **Start small**: Test with small result sets before scaling up\n",
    "4. **Check the docs**: https://docs.openalex.org for all available options\n",
    "5. **Rate limits**: 100,000 requests/day, max 10/second"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlab2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
